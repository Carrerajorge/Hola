Trabaja 30 minutos en mejorar el agente Mejora y endurece únicamente la herramienta ‘Agente’ (sin tocar ni reestructurar el chat existente): refactorízala como plugin modular con contratos tipados TS + validación runtime con Zod para Run/Step/ToolCall/Artifact, máquina de estados estricta (queued→planning→running→verifying→done/failed/cancelled/paused) con transiciones validadas e idempotency keys; añade persistencia transaccional en Postgres (agent_runs, agent_steps, opcional agent_events append-only) con índices por chatId/messageId/runId/status/created_at y correlationId; fortalece el scheduler/worker (bullmq/pg-boss) con timeouts por tool, reintentos con backoff, circuit breaker, cancel tokens que aborten ejecución real, y normaliza outputs {artifacts[], previews[], logs[], metrics[]}; implementa PolicyEngine deny-by-default por RBAC/plan + human-in-the-loop gate para herramientas sensibles; agrega observabilidad (logs estructurados, métricas por step: latency, success_rate, tool_error_rate) y endpoints compatibles (POST /api/agent/runs, GET /api/agent/runs/:id, GET /api/agent/runs/:id/events, POST /api/agent/runs/:id/{pause,resume,cancel,retry}) sin romper nada existente; entrega un CHECKLIST DE ACEPTACIÓN en replit.md con casillas verificables y evidencia: ✅ chat normal sin cambios, ✅ botón Agente activa mode='agent', ✅ panel Plan/Progreso/Artefactos, ✅ plan 3–8 pasos válido (Zod), ✅ ejecución multi-tool (upload/analyze/web/image/document) con artefactos, ✅ pause/resume/cancel/retry funcionan, ✅ polling/streaming estable, ✅ RBAC/planes aplicados, ✅ errores legibles + logs con correlationId; y añade PRUEBAS AUTOMATIZADAS + RENDIMIENTO: unit/integration/E2E (Playwright) + benchmarks (Vitest bench o Node perf hooks) midiendo (1) tiempo de plan (<1.5s con mock), (2) latencia p95 de GET /runs/:id (<200ms con DB local), (3) throughput del worker (≥10 steps/min con mocks), (4) memoria del sandbox bajo carga (límite 512MB), (5) UI render para timeline con 1,000 eventos sin jank (virtualización); genera fixtures deterministas, evita llamadas reales al LLM en tests, agrega npm run test:all y npm run perf:agent con outputs guardados en test_results/, y no consideres terminado hasta que el checklist esté 100% ✅ y todos los tests y benchmarks pasen.