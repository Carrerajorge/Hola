Implementa un módulo DATABASE MANAGEMENT enterprise-grade con conexión real a PostgreSQL/MySQL en producción: 1) BACKEND API - crear endpoints Express.js/Fastify con connection pool usando pg-pool (PostgreSQL) o mysql2/promise (MySQL), configurar variables de entorno en Replit Secrets: DATABASE_URL (formato: postgresql://user:password@host:5432/dbname?sslmode=require), DB_POOL_MIN=5, DB_POOL_MAX=50, DB_SSL=true; implementar connection health-check endpoint GET /api/db/health que retorne {status, latency_ms, active_connections, pool_size}. 2) SECURE CONNECTION LAYER - implementar SSL/TLS obligatorio para producción, connection string parsing con URL module, retry logic con exponential backoff (3 attempts, 1s/2s/4s delays), connection timeout de 10s, query timeout configurable, prepared statements para prevenir SQL injection. 3) REAL-TIME METRICS ENDPOINTS - GET /api/db/stats ejecutando: pg_stat_database para (numbackends, xact_commit, xact_rollback, blks_hit, blks_read, tup_returned, tup_fetched, tup_inserted, tup_updated, tup_deleted), pg_stat_user_tables para (relname, n_live_tup, n_dead_tup, last_vacuum, last_analyze, seq_scan, idx_scan), pg_stat_activity para (pid, usename, application_name, client_addr, state, query_start, wait_event_type, query), pg_stat_replication para (client_addr, state, sent_lsn, write_lsn, flush_lsn, replay_lsn, replay_lag), pg_database_size() y pg_total_relation_size() para storage metrics. 4) QUERY ANALYZER ENDPOINT - GET /api/db/slow-queries consultando pg_stat_statements (requiere extensión habilitada) con: SELECT queryid, query, calls, total_exec_time, mean_exec_time, rows, shared_blks_hit, shared_blks_read FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 50; endpoint POST /api/db/explain que reciba query y retorne EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON). 5) TABLES METADATA ENDPOINT - GET /api/db/tables ejecutando: SELECT schemaname, tablename, n_live_tup as rows, pg_total_relation_size(schemaname||'.'||tablename) as total_size, pg_indexes_size(schemaname||'.'||tablename) as index_size FROM pg_stat_user_tables JOIN pg_tables USING (tablename) ORDER BY n_live_tup DESC. 6) INDEX ANALYSIS ENDPOINT - GET /api/db/indexes para unused: SELECT indexrelname, idx_scan, pg_size_pretty(pg_relation_size(indexrelid)) FROM pg_stat_user_indexes WHERE idx_scan = 0 AND indexrelname NOT LIKE 'pg_%'; para bloat estimation usar pgstattuple extension o bloat estimation query. 7) BACKUP MANAGEMENT - integrar con pg_dump via child_process.spawn() para manual backups, almacenar en Replit storage o S3 presigned URLs, endpoint POST /api/db/backup/trigger y GET /api/db/backup/list. 8) CONNECTION POOLING MONITOR - GET /api/db/pool retornando: {total: pool.totalCount, idle: pool.idleCount, waiting: pool.waitingCount}; implementar event listeners pool.on('error'), pool.on('connect'), pool.on('acquire'), pool.on('release') para logging. 9) WEBSOCKET STREAMING - implementar Socket.io server que emita cada 5s: métricas actualizadas consultando pg_stat_database, connections count, replication lag; cliente se suscribe a 'db:metrics' channel. 10) FRONTEND DASHBOARD - consumir todos los endpoints con React Query (useQuery con refetchInterval para polling, o WebSocket para real-time), mostrar: cluster health indicator basado en (connection_success AND replication_lag < 100ms AND error_rate < 1%), tables list con virtual scrolling, slow queries con syntax highlighting (react-syntax-highlighter), gauges para connections/cache_hit usando recharts RadialBarChart, line charts para QPS/latency histórico. 11) SECURITY MIDDLEWARE - implementar rate limiting (express-rate-limit: 100 req/min para stats, 10 req/min para heavy queries), authentication middleware verificando API key en header X-API-Key contra ADMIN_API_KEY en secrets, audit logging de todas las operaciones DDL. 12) ERROR HANDLING - try/catch en todos los queries, mapear pg error codes a user-friendly messages, never expose raw SQL errors to frontend, implementar circuit breaker pattern que después de 5 failures consecutivos retorne cached data o degraded status. 13) ENVIRONMENT CONFIG - crear archivo .env.example documentando todas las variables requeridas, validar al startup que DATABASE_URL existe y es válida, log sanitizado de connection (host:port/dbname sin password). 14) MIGRATIONS AWARENESS - endpoint GET /api/db/migrations/status que consulte schema_migrations o alembic_version table para mostrar current version y pending migrations count.