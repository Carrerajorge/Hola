import { openai, MODELS } from "../lib/openai";
import { llmGateway } from "../lib/llmGateway";
import { geminiChat, geminiStreamChat, GEMINI_MODELS, GeminiChatMessage } from "../lib/gemini";
import { LIMITS, MEMORY_INTENT_KEYWORDS } from "../lib/constants";
import { storage } from "../storage";
import { generateEmbedding } from "../embeddingService";
import { searchWeb, searchScholar, needsWebSearch, needsAcademicSearch } from "./webSearch";
import { routeMessage, runPipeline, ProgressUpdate, checkDomainPolicy, checkRateLimit, sanitizeUrl, isValidObjective, multiIntentManager, multiIntentPipeline } from "../agent";
import type { PipelineResponse } from "../../shared/schemas/multiIntent";
import { checkToolPolicy, logToolCall } from "./integrationPolicyService";
import { detectEmailIntent, handleEmailChatRequest } from "./gmailChatIntegration";
import { productionWorkflowRunner, classifyIntent, isGenerationIntent } from "../agent/registry/productionWorkflowRunner";
import { agentLoopFacade, promptAnalyzer, type ComplexityLevel } from "../agent/orchestration";
import { buildSystemPromptWithContext, isToolAllowed, getEnforcedModel, type GptSessionContract } from "./gptSessionService";
import { intentEnginePipeline, type PipelineOptions } from "../intent-engine";
import OpenAI from "openai";

const AGENTIC_PIPELINE_ENABLED = process.env.AGENTIC_PIPELINE_ENABLED === 'true';

// Simple in-memory cache for search results (5 minute TTL)
const searchCache = new Map<string, { results: any; timestamp: number }>();
const CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes

function getCachedSearch(query: string): any | null {
  const normalizedQuery = query.toLowerCase().trim();
  const cached = searchCache.get(normalizedQuery);
  if (cached && Date.now() - cached.timestamp < CACHE_TTL_MS) {
    console.log(`[ChatService] CACHE HIT for: ${normalizedQuery.slice(0, 30)}...`);
    return cached.results;
  }
  return null;
}

function setCachedSearch(query: string, results: any): void {
  const normalizedQuery = query.toLowerCase().trim();
  searchCache.set(normalizedQuery, { results, timestamp: Date.now() });
  // Clean old entries if cache gets too big
  if (searchCache.size > 100) {
    const oldest = Array.from(searchCache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp)[0];
    if (oldest) searchCache.delete(oldest[0]);
  }
}

export type LLMProvider = "xai" | "gemini";

export const AVAILABLE_MODELS = {
  xai: {
    name: "xAI Grok",
    models: [
      { id: "grok-4-1-fast-non-reasoning", name: "Grok 4.1 Fast", description: "Respuestas r√°pidas con 2M de contexto", default: true },
      { id: "grok-4-1-fast-reasoning", name: "Grok 4.1 Fast Reasoning", description: "Razonamiento avanzado con 2M de contexto" },
      { id: "grok-4-fast-non-reasoning", name: "Grok 4 Fast", description: "Modelo r√°pido y eficiente" },
      { id: "grok-4-fast-reasoning", name: "Grok 4 Fast Reasoning", description: "Razonamiento paso a paso" },
      { id: "grok-code-fast-1", name: "Grok Code", description: "Especializado en c√≥digo" },
      { id: "grok-4-0709", name: "Grok 4 Premium", description: "Modelo premium de alta calidad" },
      { id: "grok-3-fast", name: "Grok 3 Fast", description: "Respuestas r√°pidas" },
      { id: "grok-2-vision-1212", name: "Grok 2 Vision", description: "Comprensi√≥n de im√°genes" },
    ]
  },
  gemini: {
    name: "Google Gemini",
    models: [
      { id: "gemini-3-flash-preview", name: "Gemini 3 Flash Preview", description: "El m√°s nuevo y r√°pido" },
      { id: "gemini-2.5-flash", name: "Gemini 2.5 Flash", description: "R√°pido y eficiente" },
      { id: "gemini-2.5-pro", name: "Gemini 2.5 Pro", description: "El m√°s capaz" },
    ]
  }
} as const;

export const DEFAULT_PROVIDER = "xai";
export const DEFAULT_MODEL = "grok-4-1-fast-non-reasoning";

interface ChatMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

interface GptConfig {
  id: string;
  systemPrompt: string;
  temperature: number;
  topP: number;
}

// GPT Session Info - supports both new contract-based sessions and legacy gptConfig
export interface GptSessionInfo {
  contract: GptSessionContract | null;
  // Legacy support - will be deprecated
  legacyConfig?: {
    id: string;
    systemPrompt: string;
    temperature: number;
    topP: number;
  };
}

interface DocumentMode {
  type: "word" | "excel" | "ppt";
}

type DiagramType = "flowchart" | "orgchart" | "mindmap";

interface FigmaDiagram {
  diagramType: DiagramType;
  nodes: Array<{
    id: string;
    type: "start" | "end" | "process" | "decision" | "role" | "department" | "person";
    label: string;
    x: number;
    y: number;
    level?: number;
    parentId?: string;
  }>;
  connections: Array<{
    from: string;
    to: string;
    label?: string;
  }>;
  title?: string;
}

function detectDiagramType(prompt: string): DiagramType {
  const lowerPrompt = prompt.toLowerCase();
  const orgChartKeywords = ["organigrama", "org chart", "estructura organizacional", "jerarqu", "organizaci√≥n", "equipo", "departamento", "ceo", "director", "gerente", "jefe"];
  const mindmapKeywords = ["mapa mental", "mindmap", "lluvia de ideas", "brainstorm"];

  if (orgChartKeywords.some(kw => lowerPrompt.includes(kw))) return "orgchart";
  if (mindmapKeywords.some(kw => lowerPrompt.includes(kw))) return "mindmap";
  return "flowchart";
}

function detectMemoryIntent(message: string): boolean {
  const lowerMessage = message.toLowerCase();
  return MEMORY_INTENT_KEYWORDS.some(keyword => lowerMessage.includes(keyword));
}

interface AgenticContext {
  hasAttachments: boolean;
  hasActiveDocuments: boolean;
  conversationLength: number;
}

function shouldUseAgenticPipeline(message: string, context: AgenticContext): boolean {
  const lowerMessage = message.toLowerCase();

  const COMPLEX_PATTERNS = [
    /\b(investiga|research|analiza\s+a\s+fondo|deep\s+dive)\b/i,
    /\b(crea|genera|build|create)\b.*\b(y|and|then|luego|despu√©s)\b/i,
    /\b(primero|segundo|tercero|step\s+\d+|paso\s+\d+)\b/i,
    /\b(compara|compare)\b.*\b(con|with|and|y)\b/i,
    /\b(recopila|gather|collect)\b.*\b(informaci√≥n|datos|data|info)\b/i,
    /\b(multi-?step|m√∫ltiples?\s+pasos?|varios?\s+tareas?)\b/i,
    /\b(planifica|plan|dise√±a|design)\b.*\b(estrategia|strategy|proyecto|project)\b/i,
    /\b(resume|summarize)\b.*\b(y|and)\b.*\b(crea|genera|create)\b/i,
    /\b(busca|search|find)\b.*\b(y|and|then)\b.*\b(crea|genera|create)\b/i,
    // NEW: Research + artifact generation combinations (Spanish/English)
    /\b(busca(me)?|encuentra(me)?|dame)\b.*\d+\s*(art[i√≠]culos?|tesis|papers?|informaci[o√≥]n).*\b(excel|hoja\s+de\s+c[a√°]lculo|spreadsheet|documento|word|pdf|pptx?|presentaci[o√≥]n)\b/i,
    /\b(busca(me)?|encuentra(me)?|dame|search|find|get)\b.*\b(y|and)\b.*\b(col[o√≥]ca(lo)?|pon(lo)?|exporta|genera|crea|guarda)\b.*\b(excel|documento|word|spreadsheet)\b/i,
    /\b(col[o√≥]ca(lo)?|pon(lo|erlo)?|exporta(lo)?|guarda(lo)?)\b.*\b(en\s+)?(un\s+)?(excel|hoja\s+de\s+c[a√°]lculo|spreadsheet|documento|word)\b/i,
    /\b(genera|crea|build|create)\b.*\b(excel|spreadsheet|documento|word|pdf)\b.*\b(con|with)\b.*\d+/i,
    /\b\d+\s*(art[i√≠]culos?|tesis|papers?|items?|elementos?)\b.*\b(tabla|table|lista|list|excel|spreadsheet)\b/i,
  ];

  const SIMPLE_PATTERNS = [
    /^(hola|hello|hi|hey|buenos?\s+d[i√≠]as?|buenas?\s+tardes?|buenas?\s+noches?)$/i,
    /^(gracias|thanks|ok|s√≠|no|claro|vale|perfecto)$/i,
    /^(qu√©|cu√°l|qui√©n|d√≥nde|cu√°ndo|what|who|where|when|how)\s+\w{1,20}(\?)?$/i,
  ];

  if (SIMPLE_PATTERNS.some(p => p.test(message.trim()))) {
    return false;
  }

  if (context.hasActiveDocuments && context.hasAttachments) {
    return false;
  }

  if (COMPLEX_PATTERNS.some(p => p.test(lowerMessage))) {
    console.log(`[ChatService:AgenticPipeline] Complex pattern matched for: "${message.slice(0, 50)}..."`);
    return true;
  }

  const wordCount = message.split(/\s+/).filter(w => w.length > 0).length;
  const hasMultipleClauses = (message.match(/[,;]/g) || []).length >= 2;
  const hasListMarkers = /(\d+\.|[-‚Ä¢])\s+/g.test(message);

  if (wordCount > 50 && (hasMultipleClauses || hasListMarkers)) {
    console.log(`[ChatService:AgenticPipeline] Complex message structure detected: ${wordCount} words, clauses: ${hasMultipleClauses}, lists: ${hasListMarkers}`);
    return true;
  }

  return false;
}

function validateOrgChart(diagram: FigmaDiagram): { valid: boolean; errors: string[] } {
  const errors: string[] = [];

  const hasStartEnd = diagram.nodes.some(n => n.type === "start" || n.type === "end");
  if (hasStartEnd) errors.push("Org charts should not have start/end nodes");

  const invalidWords = ["inicio", "fin", "start", "end", "aleta"];
  const validOrgTypes = ["role", "department", "person"];

  diagram.nodes.forEach(node => {
    if (invalidWords.some(w => node.label.toLowerCase() === w)) {
      errors.push(`Invalid label: ${node.label}`);
    }
    if (!validOrgTypes.includes(node.type)) {
      errors.push(`Invalid node type for org chart: ${node.type}`);
    }
  });

  const nodeIds = new Set(diagram.nodes.map(n => n.id));
  const childIds = new Set(diagram.connections.map(c => c.to));
  const roots = diagram.nodes.filter(n => !childIds.has(n.id));
  if (roots.length !== 1) errors.push(`Expected 1 root, found ${roots.length}`);

  const parentCount = new Map<string, number>();
  diagram.connections.forEach(conn => {
    const count = parentCount.get(conn.to) || 0;
    parentCount.set(conn.to, count + 1);
  });
  parentCount.forEach((count, nodeId) => {
    if (count > 1) errors.push(`Node ${nodeId} has multiple parents (${count})`);
  });

  function hasCycle(): boolean {
    const visited = new Set<string>();
    const recStack = new Set<string>();
    const childrenMap = new Map<string, string[]>();
    diagram.connections.forEach(conn => {
      const children = childrenMap.get(conn.from) || [];
      children.push(conn.to);
      childrenMap.set(conn.from, children);
    });

    function dfs(nodeId: string): boolean {
      visited.add(nodeId);
      recStack.add(nodeId);
      for (const child of childrenMap.get(nodeId) || []) {
        if (!visited.has(child)) {
          if (dfs(child)) return true;
        } else if (recStack.has(child)) {
          return true;
        }
      }
      recStack.delete(nodeId);
      return false;
    }

    for (const node of diagram.nodes) {
      if (!visited.has(node.id) && dfs(node.id)) return true;
    }
    return false;
  }

  if (hasCycle()) errors.push("Org chart contains cycles");

  return { valid: errors.length === 0, errors };
}

function applyTreeLayout(diagram: FigmaDiagram): FigmaDiagram {
  if (diagram.diagramType !== "orgchart") return diagram;

  const nodeMap = new Map(diagram.nodes.map(n => [n.id, n]));
  const childrenMap = new Map<string, string[]>();
  const childIds = new Set(diagram.connections.map(c => c.to));

  diagram.connections.forEach(conn => {
    const children = childrenMap.get(conn.from) || [];
    children.push(conn.to);
    childrenMap.set(conn.from, children);
  });

  const root = diagram.nodes.find(n => !childIds.has(n.id));
  if (!root) return diagram;

  const NODE_WIDTH = 140;
  const NODE_HEIGHT = 50;
  const HORIZONTAL_GAP = 40;
  const VERTICAL_GAP = 80;

  const subtreeWidthCache = new Map<string, number>();
  const visited = new Set<string>();

  function getSubtreeWidth(nodeId: string): number {
    if (subtreeWidthCache.has(nodeId)) return subtreeWidthCache.get(nodeId)!;
    if (visited.has(nodeId)) return NODE_WIDTH;
    visited.add(nodeId);

    const children = childrenMap.get(nodeId) || [];
    const width = children.length === 0
      ? NODE_WIDTH
      : children.reduce((sum, childId) => sum + getSubtreeWidth(childId), 0) + (children.length - 1) * HORIZONTAL_GAP;

    subtreeWidthCache.set(nodeId, width);
    return width;
  }

  const positioned = new Set<string>();

  function positionNode(nodeId: string, x: number, y: number, level: number) {
    if (positioned.has(nodeId)) return;
    positioned.add(nodeId);

    const node = nodeMap.get(nodeId);
    if (!node) return;

    node.x = x;
    node.y = y;
    node.level = level;

    const children = childrenMap.get(nodeId) || [];
    if (children.length === 0) return;

    const totalWidth = children.reduce((sum, childId) => sum + getSubtreeWidth(childId), 0) + (children.length - 1) * HORIZONTAL_GAP;
    let childX = x - totalWidth / 2 + NODE_WIDTH / 2;

    children.forEach(childId => {
      const childWidth = getSubtreeWidth(childId);
      positionNode(childId, childX + childWidth / 2 - NODE_WIDTH / 2, y + NODE_HEIGHT + VERTICAL_GAP, level + 1);
      childX += childWidth + HORIZONTAL_GAP;
    });
  }

  positionNode(root.id, 400, 50, 0);

  return diagram;
}

interface ChatSource {
  fileName: string;
  content: string;
}

interface WebSource {
  url: string;
  title: string;
  domain: string;
  favicon?: string;
  snippet?: string;
  date?: string;
  imageUrl?: string;
  canonicalUrl?: string;
  siteName?: string;
  source?: {
    name: string;
    domain: string;
  };
}

interface ChatResponse {
  content: string;
  role: string;
  sources?: ChatSource[];
  webSources?: WebSource[];
  agentRunId?: string;
  wasAgentTask?: boolean;
  pipelineSteps?: number;
  pipelineSuccess?: boolean;
  browserSessionId?: string | null;
  figmaDiagram?: FigmaDiagram;
  multiIntentResponse?: PipelineResponse;
  // GPT Session metadata - included when a session contract is active
  gpt_id?: string;
  config_version?: number;
  tool_permissions?: {
    mode: 'allowlist' | 'denylist';
    allowedTools: string[];
    actionsEnabled: boolean;
  };
  // Agent Verifier Metadata (Improvement 1)
  metadata?: {
    verified?: boolean;
    verificationAttempts?: number;
    [key: string]: any;
  };
  artifact?: any;
  artifacts?: any[];
  agenticMetadata?: any;
  documentAgenticMetadata?: any;
}

function broadcastAgentUpdate(runId: string, update: any) {
}

export async function handleChatRequest(
  messages: ChatMessage[],
  options: {
    useRag?: boolean;
    conversationId?: string;
    userId?: string;
    images?: string[];
    onAgentProgress?: (update: ProgressUpdate) => void;
    gptSession?: GptSessionInfo;
    gptConfig?: GptConfig; // Legacy - kept for backward compatibility
    documentMode?: DocumentMode;
    figmaMode?: boolean;
    provider?: LLMProvider;
    model?: string;
    attachmentContext?: string;
    forceDirectResponse?: boolean;
    hasRawAttachments?: boolean;
    lastImageBase64?: string;
    lastImageId?: string;
  } = {}
): Promise<ChatResponse> {
  const { useRag = true, conversationId, userId, images, onAgentProgress, gptSession, gptConfig, documentMode, figmaMode, provider = DEFAULT_PROVIDER, model = DEFAULT_MODEL, attachmentContext = "", forceDirectResponse = false, hasRawAttachments = false, lastImageBase64, lastImageId } = options;
  const hasImages = images && images.length > 0;

  // Fetch user settings for feature flags and preferences
  let userSettings: Awaited<ReturnType<typeof storage.getUserSettings>> = null;
  let companyKnowledge: Awaited<ReturnType<typeof storage.getActiveCompanyKnowledge>> = [];
  if (userId) {
    try {
      userSettings = await storage.getUserSettings(userId);
      companyKnowledge = await storage.getActiveCompanyKnowledge(userId);
    } catch (error) {
      console.error("Error fetching user settings or company knowledge:", error);
    }
  }

  // Extract feature flags with defaults
  // These flags control tool availability:
  // - memoryEnabled: controls RAG/document memory retrieval
  // - webSearchAuto: controls automatic web search triggering
  // - codeInterpreterEnabled: controls code execution for charts/visualizations
  // - connectorSearchAuto: controls automatic connector searches (TODO: implement in orchestrator/agent pipeline)
  // - canvasEnabled: controls canvas/visualization features
  // - voiceEnabled: controls voice input/output features
  const featureFlags = {
    memoryEnabled: userSettings?.featureFlags?.memoryEnabled ?? false,
    webSearchAuto: userSettings?.featureFlags?.webSearchAuto ?? false,
    codeInterpreterEnabled: userSettings?.featureFlags?.codeInterpreterEnabled ?? true,
    connectorSearchAuto: userSettings?.featureFlags?.connectorSearchAuto ?? false,
    canvasEnabled: userSettings?.featureFlags?.canvasEnabled ?? true,
    voiceEnabled: userSettings?.featureFlags?.voiceEnabled ?? true,
  };

  // Tool Policy Enforcement Helper
  const enforcePolicyCheck = async (toolId: string, providerId: string): Promise<{ allowed: boolean; reason?: string }> => {
    if (!userId) return { allowed: true };
    try {
      const check = await checkToolPolicy(userId, toolId, providerId);
      if (!check.allowed) {
        console.log(`[ToolPolicy] Blocked ${toolId} for user ${userId}: ${check.reason}`);
      }
      return check;
    } catch (error) {
      console.error(`[ToolPolicy] Error checking policy for ${toolId}:`, error);
      return { allowed: true };
    }
  };

  // Intent Engine Pipeline Integration
  // Processes user message to extract intent, constraints, and quality metrics
  // Results are used to influence routing decisions and system prompt construction
  let intentEngineResult: Awaited<ReturnType<typeof intentEnginePipeline.process>> | null = null;
  const lastMessage = messages.filter(m => m.role === "user").pop();
  if (lastMessage && userId && conversationId) {
    try {
      const pipelineOptions: PipelineOptions = {
        sessionId: conversationId,
        userId: userId,
        skipQualityGate: false,
        skipSelfHeal: false
      };
      intentEngineResult = await intentEnginePipeline.process(lastMessage.content, pipelineOptions);
      if (intentEngineResult.success) {
        console.log(`[IntentEngine] Processed: intent=${intentEngineResult.context.intent?.primaryIntent}, quality=${intentEngineResult.qualityScore}`);
      }
    } catch (error) {
      console.error("[IntentEngine] Pipeline error:", error);
    }
  }

  // Use intent engine results to enhance routing decisions
  const intentContext = intentEngineResult?.success ? {
    primaryIntent: intentEngineResult.context.intent?.primaryIntent,
    constraints: intentEngineResult.context.constraints,
    qualityScore: intentEngineResult.qualityScore,
    isMultiIntent: (intentEngineResult.context.intent?.subIntents?.length || 0) > 1
  } : null;

  // Extract response preferences
  const customInstructions = userSettings?.responsePreferences?.customInstructions || "";
  const responseStyle = userSettings?.responsePreferences?.responseStyle || "default";

  // Extract user profile for context
  const userProfile = userSettings?.userProfile || null;

  // Load persistent conversation documents for context continuity
  let persistentDocumentContext = "";
  if (conversationId) {
    try {
      const conversationDocs = await storage.getConversationDocuments(conversationId);
      if (conversationDocs.length > 0) {
        const parts: string[] = ["\n\n=== DOCUMENTOS DE ESTA CONVERSACI√ìN ===\n"];
        for (const doc of conversationDocs) {
          parts.push(`\n--- Archivo: ${doc.fileName} ---\n`);
          parts.push(doc.extractedText || "[Sin contenido extra√≠do]");
          parts.push("\n--- Fin del archivo ---\n");
        }
        persistentDocumentContext = parts.join("");
        console.log(`[ChatService] Loaded ${conversationDocs.length} persistent document(s) for conversation ${conversationId}`);
      }
    } catch (error) {
      console.error("[ChatService] Error loading conversation documents:", error);
    }
  }

  // GPT Session Resolution
  // Priority: gptSession.contract (new immutable) > gptSession.legacyConfig > gptConfig (legacy)
  let activeSessionContract: GptSessionContract | null = null;
  let validatedGptConfig = gptConfig;
  let effectiveModel = model;

  if (gptSession?.contract) {
    // Use the immutable contract directly - no additional validation needed
    activeSessionContract = gptSession.contract;
    effectiveModel = getEnforcedModel(activeSessionContract, model);
    console.log(`[ChatService] Using GPT Session Contract: gptId=${activeSessionContract.gptId}, version=${activeSessionContract.configVersion}, model=${effectiveModel}`);

    // Track usage for the GPT
    storage.incrementGptUsage(activeSessionContract.gptId).catch(console.error);
  } else if (gptSession?.legacyConfig) {
    // Legacy config passed through - use as-is
    validatedGptConfig = gptSession.legacyConfig;
    console.log(`[ChatService] Using legacy GPT config: id=${validatedGptConfig.id}`);
    storage.incrementGptUsage(validatedGptConfig.id).catch(console.error);
  } else if (gptConfig?.id) {
    // Old API path - validate and load fresh
    try {
      const gpt = await storage.getGpt(gptConfig.id);
      if (gpt) {
        validatedGptConfig = {
          id: gpt.id,
          systemPrompt: gpt.systemPrompt,
          temperature: parseFloat(gpt.temperature || "0.7"),
          topP: parseFloat(gpt.topP || "1")
        };
        storage.incrementGptUsage(gpt.id).catch(console.error);
      } else {
        validatedGptConfig = undefined;
      }
    } catch (error) {
      console.error("Error loading GPT config:", error);
      validatedGptConfig = undefined;
    }
  }

  const lastUserMessage = messages.filter(m => m.role === "user").pop();

  if (lastUserMessage) {
    // GMAIL INTEGRATION: Detectar y manejar solicitudes de correo electr√≥nico
    // Skip Gmail detection when user has attached a document (attachmentContext contains the file)
    if (!documentMode && !figmaMode && !attachmentContext && userId && detectEmailIntent(lastUserMessage.content)) {
      try {
        const emailResult = await handleEmailChatRequest(userId, lastUserMessage.content);
        if (emailResult.handled && emailResult.response) {
          console.log(`[Gmail Chat] Handled email query for user ${userId}`);
          return {
            content: emailResult.response,
            role: "assistant"
          };
        }
      } catch (error) {
        console.error("[Gmail Chat] Error handling email request:", error);
      }
    }

    // ========================================================================
    // AGGRESSIVE FIX: Simple search queries execute IMMEDIATELY and return
    // This completely bypasses ALL pipeline/routing/multi-intent logic
    // ULTRA-INCLUSIVE patterns to catch ALL search variations
    // ========================================================================
    const SIMPLE_SEARCH_PATTERNS_EARLY = [
      // Spanish patterns - with and without accents
      /dame\s+\d*\s*(noticias|art[i√≠]culos?|tesis|informaci[o√≥]n)/i,
      /busca(me)?\s+\d*\s*(noticias|informaci[o√≥]n|info|art[i√≠]culos?|tesis)/i,
      /b[u√∫]sca(me)?\s+\d*/i,  // Catch all "buscame X" variations
      /noticias\s+(de|sobre|del)/i,
      /[u√∫]ltimas?\s+noticias/i,
      /qu[e√©]\s+(est[a√°]\s+pasando|pasa|hay\s+de\s+nuevo)/i,
      /precio\s+(de|del|actual)/i,
      /clima\s+(en|de)/i,
      /quisiera\s+(que\s+)?(me\s+)?ayud(es|a)\s+a\s+buscar/i,
      /ay[u√∫]dame\s+a\s+buscar/i,
      /buscar\s+\d*\s*(art[i√≠]culos?|tesis|informaci[o√≥]n|noticias)/i,
      /dame\s+\d*\s*(art[i√≠]culos?|tesis)/i,
      /encuentra(me)?\s+\d*\s*(art[i√≠]culos?|informaci[o√≥]n|tesis)/i,
      /investiga\s+(sobre|acerca|de)/i,
      /informaci[o√≥]n\s+(sobre|de|del|acerca)/i,
      // English patterns
      /what('s|\s+is)\s+(happening|new|going\s+on)/i,
      /news\s+(about|from|on)/i,
      /weather\s+(in|for)/i,
      /search\s+for/i,
      /find\s+(me\s+)?\d*/i,
      /look\s+for/i,
      /get\s+me\s+\d*/i,
      // Generic patterns - ANY request with numbers + content types
      /\d+\s*(noticias|art[i√≠]culos?|tesis|papers?|resultados?)/i,
      // Fallback: starts with search-like verbs
      /^(busca|encuentra|investiga|dame|dime|muestrame|search|find|look)/i,
    ];

    // Ultra-aggressive: normalize text by removing accents for matching
    const normalizeText = (text: string) =>
      text.normalize('NFD').replace(/[\u0300-\u036f]/g, '').toLowerCase();

    const isSimpleSearchQueryEarly = (text: string) => {
      const normalized = normalizeText(text);

      // GUARD: If message contains artifact generation keywords, it's NOT a simple search
      // These should be routed to the agentic pipeline instead
      const ARTIFACT_KEYWORDS = /\b(excel|spreadsheet|hoja\s*de\s*c[a√°]lculo|documento|word|pdf|pptx?|presentaci[o√≥]n|slides?|genera|crea|exporta|col[o√≥]ca(lo)?|pon(lo|erlo)?|guarda(lo)?)\b/i;
      if (ARTIFACT_KEYWORDS.test(text) || ARTIFACT_KEYWORDS.test(normalized)) {
        console.log(`[ChatService] Artifact keyword detected in query, skipping simple search path`);
        return false;
      }

      // Check patterns against both original and normalized
      return SIMPLE_SEARCH_PATTERNS_EARLY.some(p => p.test(text) || p.test(normalized));
    };

    // INTENT GUARD SYSTEM: Detect intent and enforce response contracts
    // This prevents context contamination from previous sessions/templates
    // CRITICAL: Include hasRawAttachments to ensure we catch attachments even if extraction failed
    const hasActiveDocuments = persistentDocumentContext.length > 0 || (attachmentContext && attachmentContext.length > 0) || hasRawAttachments;

    console.log(`[IntentGuard] PRE-CHECK: persistentDocLen=${persistentDocumentContext.length}, attachmentLen=${attachmentContext?.length || 0}, hasRawAttachments=${hasRawAttachments}, hasActiveDocuments=${hasActiveDocuments}`);

    // AGGRESSIVE DOCUMENT PRIORITY: If there's any document content, handle it FIRST before any search logic
    if (hasActiveDocuments && lastUserMessage) {
      console.log(`[IntentGuard] DOCUMENT DETECTED - Entering document analysis flow`);

      const { detectIntent, validateResponse, buildDocumentPrompt, createAuditLog } = await import("./intentGuard");

      const intentContract = detectIntent(
        lastUserMessage.content,
        persistentDocumentContext.length > 0,
        attachmentContext.length > 0
      );

      console.log(`[IntentGuard] Detected intent: ${intentContract.taskType}, goal: ${intentContract.userGoal}, documentPresent: ${intentContract.documentPresent}`);

      // CHECK: Does user also want to generate an OUTPUT artifact (DOCX, XLSX, PPTX)?
      // If so, skip document-only analysis and let ProductionWorkflowRunner handle it
      const outputArtifactIntent = classifyIntent(lastUserMessage.content);
      const wantsOutputArtifact = isGenerationIntent(outputArtifactIntent);

      if (wantsOutputArtifact) {
        console.log(`[IntentGuard] OUTPUT ARTIFACT REQUESTED: ${outputArtifactIntent} - Skipping document-only analysis, routing to ProductionWorkflowRunner`);
        // Fall through to ProductionWorkflowRunner handling below
      }
      // DOCUMENT ANALYSIS MODE: If document is present and task is document-related (but NO output artifact requested)
      else if (intentContract.documentPresent && intentContract.taskType.startsWith("document_")) {
        console.log("[ChatService] DOCUMENT ANALYSIS MODE: Intent contract enforced");

        const fullDocContext = persistentDocumentContext + attachmentContext;
        const documentPrompt = buildDocumentPrompt(intentContract, fullDocContext, lastUserMessage.content);

        const llmMessages = [
          { role: "system" as const, content: documentPrompt },
          { role: "user" as const, content: lastUserMessage.content }
        ];

        const MAX_RETRIES = 2;
        let attempt = 0;
        let validatorOutcome: "pass" | "fail" | "retry" = "pass";

        while (attempt <= MAX_RETRIES) {
          try {
            const llmResponse = await llmGateway.chat(llmMessages, {
              temperature: 0.3,
              maxTokens: 2500,
              model: "gemini-2.5-flash"
            });

            // Validate response against intent contract
            const validation = validateResponse(llmResponse.content, intentContract);

            if (validation.valid) {
              validatorOutcome = "pass";
              const auditLog = createAuditLog(
                intentContract,
                lastUserMessage.content,
                "document_analysis_prompt",
                validatorOutcome
              );
              console.log(`[IntentGuard] Audit: ${JSON.stringify(auditLog)}`);

              return {
                content: llmResponse.content,
                role: "assistant"
              };
            } else {
              validatorOutcome = attempt < MAX_RETRIES ? "retry" : "fail";
              console.warn(`[IntentGuard] INTENT_MISMATCH_ERROR: ${validation.matchedProhibitedPattern}, attempt ${attempt + 1}/${MAX_RETRIES + 1}`);

              if (attempt < MAX_RETRIES && validation.suggestedRetryPrompt) {
                llmMessages[0].content = documentPrompt + "\n\nCORRECCI√ìN IMPORTANTE:\n" + validation.suggestedRetryPrompt;
                attempt++;
                continue;
              }

              const auditLog = createAuditLog(
                intentContract,
                lastUserMessage.content,
                "document_analysis_prompt",
                validatorOutcome,
                validation.error
              );
              console.error(`[IntentGuard] Validation failed after retries: ${JSON.stringify(auditLog)}`);

              return {
                content: `**Error de an√°lisis**: El sistema detect√≥ una inconsistencia en la respuesta. Por favor, reformula tu pregunta sobre el documento.`,
                role: "assistant"
              };
            }
          } catch (docError: any) {
            console.error("[ChatService] Document analysis error:", docError);
            return {
              content: `**Error al analizar el documento**: ${docError.message || "No se pudo procesar el contenido del archivo. Por favor, intenta de nuevo o reformula tu pregunta."}`,
              role: "assistant"
            };
          }
        }
      }
    }

    // DETERMINISTIC PIPELINE: Search + Analyze + Create Document
    // 8-stage sequential pipeline: search ‚Üí download ‚Üí analyze ‚Üí extract_data ‚Üí generate_charts ‚Üí generate_images ‚Üí validate ‚Üí assemble
    const SEARCH_AND_CREATE_PATTERN = /busca\s+(\d+)\s*(art√≠culos?|fuentes?|referencias?).*(crea|genera|haz|hacer).*(ppt|powerpoint|presentaci[o√≥]n|word|documento|excel)/i;
    if (lastUserMessage && SEARCH_AND_CREATE_PATTERN.test(lastUserMessage.content) && !documentMode && !figmaMode) {
      console.log(`[ChatService:DeterministicPipeline] Detected search + create pattern`);

      try {
        const match = lastUserMessage.content.match(SEARCH_AND_CREATE_PATTERN);
        const requestedCount = match ? parseInt(match[1], 10) : 10;
        const isPPT = /ppt|powerpoint|presentaci[o√≥]n/i.test(lastUserMessage.content);
        const hasAPA = /apa|bibliograf[i√≠]a|referencias?|citas?/i.test(lastUserMessage.content);

        console.log(`[ChatService:DeterministicPipeline] Count: ${requestedCount}, PPT: ${isPPT}, APA: ${hasAPA}`);

        if (isPPT) {
          // Use the new 8-stage deterministic pipeline
          const { DeterministicPipeline } = await import("../agent/pipelines/deterministicPipeline");
          const pipeline = new DeterministicPipeline();

          // Subscribe to stage events for logging
          pipeline.on("stage_start", ({ stage, index }) => {
            console.log(`[DeterministicPipeline] Stage ${index + 1}/8: ${stage} started`);
          });
          pipeline.on("stage_complete", ({ stage, index, duration, inputCount, outputCount }) => {
            console.log(`[DeterministicPipeline] Stage ${index + 1}/8: ${stage} completed in ${duration}ms (${inputCount} ‚Üí ${outputCount})`);
          });

          const result = await pipeline.execute(lastUserMessage.content, {
            maxSources: requestedCount,
            includeAcademic: hasAPA,
            includeWeb: true,
            generateImages: true,
            imageCount: 3,
            apaCitation: hasAPA,
            slideTemplate: hasAPA ? "academic" : "standard",
          });

          if (result.success && result.artifact) {
            // Save artifact to disk
            const fs = await import("fs");
            const path = await import("path");
            const artifactsDir = path.join(process.cwd(), "artifacts");
            if (!fs.existsSync(artifactsDir)) {
              fs.mkdirSync(artifactsDir, { recursive: true });
            }

            const filename = `presentation_${Date.now()}.pptx`;
            const filepath = path.join(artifactsDir, filename);
            fs.writeFileSync(filepath, result.artifact.buffer);

            const state = result.state;
            const sources = state.sources.slice(0, requestedCount);

            // Build traceability summary
            const stagesSummary = result.traceability.stages
              .map(s => `${s.stage}: ${s.duration}ms`)
              .join(" ‚Üí ");

            return {
              content: `He creado una presentaci√≥n profesional sobre **${state.topic}** usando el pipeline determinista de 8 etapas.

**üìä Resumen del proceso:**
- Fuentes encontradas: ${sources.length}
- Tablas de datos: ${state.dataTables.length}
- Gr√°ficas generadas: ${state.charts.length}
- Im√°genes generadas: ${state.images.length}
- Diapositivas: ${state.slides.length}

**üìö Fuentes consultadas:**
${sources.slice(0, 10).map((s, i) => `${i + 1}. ${s.title} (${s.year})`).join("\n")}

**‚è±Ô∏è Tiempo total:** ${(result.traceability.totalDurationMs / 1000).toFixed(1)}s
**‚úì Validaci√≥n:** ${state.validation?.passed ? "Aprobada" : "Con observaciones"} (${((state.validation?.score || 0) * 100).toFixed(0)}%)${hasAPA ? `\n\n**üìñ Bibliograf√≠a APA 7ma ed.:** Incluida en la √∫ltima diapositiva` : ""}`,
              role: "assistant",
              artifact: {
                type: "presentation",
                mimeType: result.artifact.mimeType,
                downloadUrl: `/api/artifacts/${filename}`,
                contentUrl: `/api/artifacts/${filename}/content`,
                sizeBytes: result.artifact.sizeBytes,
              },
              pipelineTraceability: {
                stages: stagesSummary,
                reproducible: result.traceability.reproducible,
                totalDurationMs: result.traceability.totalDurationMs,
              }
            };
          } else {
            console.warn(`[ChatService:DeterministicPipeline] Pipeline failed:`, result.state.error);
          }
        }

        // Fallback for non-PPT or pipeline failure: simple search + format
        const { searchScholar, searchWeb, needsAcademicSearch } = await import("./webSearch");
        const topicMatch = lastUserMessage.content.match(/sobre\s+(?:la\s+|el\s+|los\s+|las\s+)?(.+?)(?:\s+y\s+crea|\s+crea|\s+genera|\s+haz|$)/i);
        const topic = topicMatch ? topicMatch[1].trim() : "el tema solicitado";

        let searchResults: any[] = [];
        if (hasAPA || needsAcademicSearch(topic)) {
          const scholarResults = await searchScholar(topic, requestedCount);
          searchResults = scholarResults.map(r => ({
            title: r.title,
            url: r.url,
            snippet: r.snippet,
            authors: r.authors || "Autor desconocido",
            year: r.year || new Date().getFullYear().toString(),
          }));
        }

        if (searchResults.length < requestedCount) {
          const webResponse = await searchWeb(topic, requestedCount - searchResults.length);
          searchResults = [...searchResults, ...webResponse.results.map(r => ({
            title: r.title,
            url: r.url,
            snippet: r.snippet,
            authors: r.siteName || "Fuente web",
            year: r.publishedDate?.slice(0, 4) || new Date().getFullYear().toString(),
          }))];
        }

        const formattedResults = searchResults.slice(0, requestedCount).map((r, i) =>
          `**${i + 1}. ${r.title}**\n   ${r.snippet?.slice(0, 200) || "Sin descripci√≥n"}...\n   üìö ${r.authors} (${r.year})\n   üîó ${r.url}`
        ).join("\n\n");

        const apaBibliography = hasAPA ? `\n\n---\n**Referencias (APA 7ma ed.):**\n${searchResults.slice(0, requestedCount).map(r =>
          `${r.authors} (${r.year}). *${r.title}*. Recuperado de ${r.url}`
        ).join("\n\n")}` : "";

        return {
          content: `Encontr√© ${searchResults.length} art√≠culos sobre **${topic}**:\n\n${formattedResults}${apaBibliography}`,
          role: "assistant"
        };

      } catch (pipelineError: any) {
        console.error(`[ChatService:DeterministicPipeline] Error:`, pipelineError);
        // Fall through to normal flow
      }
    }

    // AGENTIC SUPER-COMPLEX PIPELINE: Planner ‚Üí Executor ‚Üí Critic loop with iterative refinement
    // Activated when user requests "agentic", "iterative", "optimize", "verify quality" modes
    const AGENTIC_COMPLEX_PATTERN = /(?:modo\s+)?(?:ag[e√©]ntico|iterativo|optimiza|verifica|calidad|planner|critic|bucle|loop|refin)/i;
    const PPT_REQUEST_PATTERN = /(?:crea|genera|haz).*(ppt|powerpoint|presentaci[o√≥]n)/i;
    if (lastUserMessage && AGENTIC_COMPLEX_PATTERN.test(lastUserMessage.content) && PPT_REQUEST_PATTERN.test(lastUserMessage.content) && !documentMode && !figmaMode) {
      console.log(`[ChatService:AgenticSuperComplex] Detected agentic pipeline request`);

      try {
        const { AgenticPipeline } = await import("../agent/pipelines/agenticPipeline");
        const agenticPipeline = new AgenticPipeline();

        // Subscribe to phase events for real-time feedback
        agenticPipeline.on("phase_start", ({ phase, iteration }) => {
          console.log(`[AgenticPipeline] Phase: ${phase}${iteration !== undefined ? ` (iteration ${iteration})` : ""}`);
        });
        agenticPipeline.on("critic_feedback", ({ feedback }) => {
          console.log(`[AgenticPipeline] Critic: ${feedback.passed ? "PASSED" : "NEEDS_REFINEMENT"} (${(feedback.metrics.overallScore * 100).toFixed(0)}%)`);
        });

        // Detect audience and goal from message
        const isAcademic = /acad[e√©]mic|universidad|tesis|paper|investigaci[o√≥]n|apa/i.test(lastUserMessage.content);
        const isExecutive = /ejecutivo|gerente|director|junta|board|resumen/i.test(lastUserMessage.content);

        const result = await agenticPipeline.execute(lastUserMessage.content, {
          audience: isAcademic ? "academic" : isExecutive ? "executive" : "general",
          goal: isAcademic ? "educate" : "inform",
          maxIterations: 3,
        });

        if (result.success && result.artifact) {
          const fs = await import("fs");
          const path = await import("path");
          const artifactsDir = path.join(process.cwd(), "artifacts");
          if (!fs.existsSync(artifactsDir)) {
            fs.mkdirSync(artifactsDir, { recursive: true });
          }

          const filename = `agentic_ppt_${Date.now()}.pptx`;
          const filepath = path.join(artifactsDir, filename);
          fs.writeFileSync(filepath, result.artifact.buffer);

          const state = result.state;
          const plan = state.plan!;
          const lastFeedback = state.iterations.length > 0 ? state.iterations[state.iterations.length - 1].feedback : null;

          const iterationsSummary = state.iterations.map((it, i) =>
            `  ${i + 1}. Score: ${(it.feedback.metrics.overallScore * 100).toFixed(0)}% - ${it.actionsCompleted.length} acciones`
          ).join("\n");

          return {
            content: `He creado una presentaci√≥n profesional sobre **${plan.topic}** usando el pipeline ag√©ntico con bucle Planner ‚Üí Executor ‚Üí Critic.

**üéØ Configuraci√≥n:**
- Audiencia: ${plan.audience}
- Objetivo: ${plan.goal}
- Duraci√≥n estimada: ${plan.duration} min
- Story Arc: ${plan.storyArc.hook}

**üìä M√©tricas de Calidad (final):**
- Cobertura de fuentes: ${((lastFeedback?.metrics.sourceCoverage || 0) * 100).toFixed(0)}%
- Coherencia narrativa: ${((lastFeedback?.metrics.narrativeCoherence || 0) * 100).toFixed(0)}%
- Grounding de evidencia: ${((lastFeedback?.metrics.evidenceGrounding || 0) * 100).toFixed(0)}%
- Score general: ${((lastFeedback?.metrics.overallScore || 0) * 100).toFixed(0)}%

**üîÑ Iteraciones de refinamiento:** ${state.iterations.length}
${iterationsSummary || "  (Ninguna - aprob√≥ en primera iteraci√≥n)"}

**üìë Estructura del deck:** ${state.slides.length} slides
**üîó Fuentes utilizadas:** ${state.sources.length}
**üìñ Claims con grounding:** ${state.evidence.filter(e => e.verified).length}/${state.evidence.length}

**üí° Insights generados:** ${state.insights.length}`,
            role: "assistant",
            artifact: {
              type: "presentation",
              mimeType: result.artifact.mimeType,
              downloadUrl: `/api/artifacts/${filename}`,
              contentUrl: `/api/artifacts/${filename}/content`,
              sizeBytes: result.artifact.sizeBytes,
            },
            agenticMetadata: {
              iterations: state.iterations.length,
              finalScore: lastFeedback?.metrics.overallScore || 0,
              grounded: state.groundingReport?.overallGroundingScore || 0,
              audience: plan.audience,
              goal: plan.goal,
            }
          };
        } else {
          console.warn(`[ChatService:AgenticSuperComplex] Pipeline failed:`, result.state.error);
        }
      } catch (agenticError: any) {
        console.error(`[ChatService:AgenticSuperComplex] Error:`, agenticError);
        // Fall through to normal flow
      }
    }

    // DOCUMENT AGENTIC PIPELINE: Word/Excel generation with Planner ‚Üí Executor ‚Üí Critic loop
    // Activated when user requests Word documents, Excel models, or reports/analysis
    const DOCUMENT_AGENTIC_PATTERN = /(?:crea|genera|haz)\s+(?:un\s+)?(?:informe|reporte|an[a√°]lisis|documento|modelo.*datos|excel|word)/i;
    const HAS_AGENTIC_KEYWORDS = /(?:ag[e√©]ntico|iterativo|optimiza|verifica|calidad|bucle|consistencia)/i;
    if (lastUserMessage && DOCUMENT_AGENTIC_PATTERN.test(lastUserMessage.content) && !documentMode && !figmaMode) {
      const isAgenticMode = HAS_AGENTIC_KEYWORDS.test(lastUserMessage.content);

      if (isAgenticMode) {
        console.log(`[ChatService:DocumentAgentic] Detected document agentic pipeline request`);

        try {
          const { DocumentAgenticPipeline } = await import("../agent/pipelines/documentAgenticPipeline");
          const docPipeline = new DocumentAgenticPipeline();

          docPipeline.on("phase_start", ({ phase, iteration }) => {
            console.log(`[DocumentAgenticPipeline] Phase: ${phase}${iteration !== undefined ? ` (iteration ${iteration})` : ""}`);
          });
          docPipeline.on("validation_result", ({ report }) => {
            console.log(`[DocumentAgenticPipeline] Validation: ${report.passed}/${report.totalChecks} passed (${(report.overallScore * 100).toFixed(0)}%)`);
          });

          const result = await docPipeline.execute(lastUserMessage.content, {
            maxIterations: 3,
          });

          if (result.success && result.artifacts.length > 0) {
            const fs = await import("fs");
            const path = await import("path");
            const artifactsDir = path.join(process.cwd(), "artifacts");
            if (!fs.existsSync(artifactsDir)) {
              fs.mkdirSync(artifactsDir, { recursive: true });
            }

            const savedArtifacts: any[] = [];
            for (const artifact of result.artifacts) {
              const filepath = path.join(artifactsDir, artifact.filename);
              fs.writeFileSync(filepath, artifact.buffer);
              savedArtifacts.push({
                type: artifact.type,
                filename: artifact.filename,
                downloadUrl: `/api/artifacts/${artifact.filename}`,
                mimeType: artifact.mimeType,
                sizeBytes: artifact.sizeBytes,
              });
            }

            const state = result.state;
            const wordPlan = state.wordPlan;
            const excelPlan = state.excelPlan;
            const validation = state.validationReport;

            const artifactsSummary = savedArtifacts.map(a =>
              `  ‚Ä¢ ${a.type === "word" ? "üìÑ Word" : "üìä Excel"}: ${a.filename}`
            ).join("\n");

            const iterationsSummary = state.iterations.map((it, i) =>
              `  ${i + 1}. Score: ${(it.validationScore * 100).toFixed(0)}% - ${it.actions.join(", ")}`
            ).join("\n");

            return {
              content: `He creado los documentos solicitados usando el pipeline ag√©ntico con bucle de validaci√≥n y refinamiento.

**üìã Configuraci√≥n:**
- Formato: ${state.outputFormat}
- Audiencia: ${state.audience}
- Objetivo: ${state.goal}

**üìä M√©tricas de Extracci√≥n:**
- Fuentes consultadas: ${state.sources.length}
- Entidades extra√≠das: ${state.extractedEntities.length}
- Tablas detectadas: ${state.extractedTables.length}
- Series temporales: ${state.timeSeries.length}
- Datasets normalizados: ${state.normalizedDatasets.length}

**‚úÖ Validaci√≥n de Consistencia:**
- Checks totales: ${validation?.totalChecks || 0}
- Aprobados: ${validation?.passed || 0}
- Advertencias: ${validation?.warnings || 0}
- Score final: ${((validation?.overallScore || 0) * 100).toFixed(0)}%

**üîÑ Iteraciones de refinamiento:** ${state.iterations.length}
${iterationsSummary || "  (Ninguna - aprob√≥ en primera iteraci√≥n)"}

**üìÅ Archivos generados:**
${artifactsSummary}

${wordPlan ? `**üìÑ Estructura Word:** ${wordPlan.chapters.length} cap√≠tulos` : ""}
${excelPlan ? `**üìä Estructura Excel:** ${excelPlan.sheets.length} hojas` : ""}`,
              role: "assistant",
              artifacts: savedArtifacts,
              documentAgenticMetadata: {
                iterations: state.iterations.length,
                validationScore: validation?.overallScore || 0,
                outputFormat: state.outputFormat,
                audience: state.audience,
                goal: state.goal,
              }
            };
          } else {
            console.warn(`[ChatService:DocumentAgentic] Pipeline failed:`, result.state.error);
          }
        } catch (docAgenticError: any) {
          console.error(`[ChatService:DocumentAgentic] Error:`, docAgenticError);
          // Fall through to normal flow
        }
      }
    }

    // AGENTIC PIPELINE: Route complex requests through AgentLoopFacade when feature flag is enabled
    // This provides multi-agent orchestration, QA verification, and SSE streaming for complex tasks
    if (AGENTIC_PIPELINE_ENABLED && lastUserMessage && !documentMode && !figmaMode && !hasImages) {
      const agenticContext: AgenticContext = {
        hasAttachments: hasRawAttachments || (attachmentContext?.length > 0) || false,
        hasActiveDocuments: hasActiveDocuments,
        conversationLength: messages.length
      };

      if (shouldUseAgenticPipeline(lastUserMessage.content, agenticContext)) {
        console.log(`[ChatService:AgenticPipeline] Routing to AgentLoopFacade for complex task`);

        try {
          const pipelineResult = await agentLoopFacade.execute(
            lastUserMessage.content,
            {
              sessionId: conversationId || `session_${Date.now()}`,
              userId: userId || "anonymous",
              chatId: conversationId || `chat_${Date.now()}`,
              messages: messages.map(m => ({
                role: m.role,
                content: m.content,
                timestamp: Date.now()
              })),
              attachments: [],
              model: model || DEFAULT_MODEL
            }
          );

          if (pipelineResult.success) {
            console.log(`[ChatService:AgenticPipeline] Pipeline completed successfully in ${pipelineResult.metadata.durationMs}ms`);

            return {
              content: pipelineResult.response.content,
              role: "assistant",
              agentRunId: pipelineResult.runId,
              wasAgentTask: true,
              pipelineSteps: pipelineResult.metadata.totalSteps,
              pipelineSuccess: true,
              metadata: {
                verified: pipelineResult.metadata.qaResult?.passed,
                verificationAttempts: pipelineResult.metadata.qaResult ? 1 : 0,
                qaResult: pipelineResult.metadata.qaResult,
                // Preserve other metadata
                agentsUsed: pipelineResult.metadata.agentsUsed,
                toolsUsed: pipelineResult.metadata.toolsUsed
              }
            };
          } else {
            console.warn(`[ChatService:AgenticPipeline] Pipeline failed, falling back to normal flow`);
          }
        } catch (agenticError: any) {
          console.error(`[ChatService:AgenticPipeline] Error executing pipeline:`, agenticError);
        }
      }
    }

    // IMMEDIATE EXECUTION: Simple searches bypass EVERYTHING and execute directly
    // Only activate if NO documents are present (documents take priority)
    if (!documentMode && !figmaMode && !hasImages && !hasActiveDocuments && lastUserMessage && isSimpleSearchQueryEarly(lastUserMessage.content)) {
      console.log("[ChatService] IMMEDIATE SEARCH EXECUTION: Bypassing all pipelines");

      // Helper to extract domain and favicon with proper source object
      const extractWebSourceImmediate = (url: string, title: string, snippet?: string, imageUrl?: string, siteName?: string, canonicalUrl?: string): WebSource => {
        let domain = "";
        try {
          const urlObj = new URL(url);
          domain = urlObj.hostname.replace(/^www\./, "");
        } catch {
          domain = url.split("/")[2]?.replace(/^www\./, "") || "unknown";
        }

        // Determine source name with fallback chain
        const sourceName = siteName || domain || "Desconocida";
        if (!siteName && !domain) {
          console.warn(`[ChatService] missing_source_count: URL ${url} has no source info`);
        }

        return {
          url,
          title,
          domain,
          favicon: `https://www.google.com/s2/favicons?domain=${domain}&sz=32`,
          snippet: snippet?.slice(0, 400),
          imageUrl,
          siteName: sourceName,
          canonicalUrl: canonicalUrl || url,
          source: {
            name: sourceName,
            domain: domain || "unknown"
          }
        };
      };

      try {
        // Check cache first for ultra-fast response
        const cached = getCachedSearch(lastUserMessage.content);
        let webSources: WebSource[] = [];

        if (cached) {
          webSources = cached;
        } else {
          // Check if academic search is needed
          const isAcademic = needsAcademicSearch(lastUserMessage.content);

          if (isAcademic) {
            const scholarResults = await searchScholar(lastUserMessage.content, 15);
            if (scholarResults.length > 0) {
              webSources = scholarResults.filter(r => r.url).map(r =>
                extractWebSourceImmediate(r.url, r.title, r.snippet, r.imageUrl, r.siteName, r.canonicalUrl)
              );
            }
          }

          // Always do web search for general results
          const searchResults = await searchWeb(lastUserMessage.content, 20);
          if (searchResults.results.length > 0) {
            webSources = [
              ...webSources,
              ...searchResults.results.slice(0, 15).map(r =>
                extractWebSourceImmediate(r.url, r.title, r.snippet, r.imageUrl, r.siteName, r.canonicalUrl)
              )
            ];
          }

          // Cache results for repeated queries
          if (webSources.length > 0) {
            setCachedSearch(lastUserMessage.content, webSources);
          }
        }

        // Build rich context for LLM with full snippets
        const topSources = webSources.slice(0, 12);
        console.log(`[ChatService] Building response with ${topSources.length} sources`);

        const richContext = topSources.map((s, i) =>
          `[${i + 1}] ${s.title}\nFuente: ${s.siteName || s.domain}\nURL: ${s.url}\nResumen: ${s.snippet || "Sin resumen disponible"}`
        ).join("\n\n");

        // General-purpose system prompt for search results
        const systemPrompt = `Eres IliaGPT, un asistente de IA vers√°til y capaz. Responde a la consulta del usuario bas√°ndote en las fuentes proporcionadas.

INSTRUCCIONES:
1. Presenta la informaci√≥n de forma clara, estructurada y √∫til
2. Si la consulta pide noticias o actualizaciones, presenta hasta 5 resultados relevantes numerados
3. Si la consulta pide informaci√≥n general, sintetiza los datos de las fuentes
4. Cada punto debe incluir al final: [Fuente: N] donde N es el n√∫mero de la fuente
5. Si la informaci√≥n es insuficiente, ind√≠calo claramente

FUENTES DISPONIBLES:
${richContext}

Responde de manera completa y profesional, adaptando el formato a lo que el usuario necesita.`;

        const llmMessages = [
          { role: "system" as const, content: systemPrompt },
          { role: "user" as const, content: lastUserMessage.content }
        ];

        // Use faster model with enough tokens for complete response
        const llmResponse = await Promise.race([
          llmGateway.chat(llmMessages, {
            temperature: 0.7,
            maxTokens: 1500,
            model: "gemini-2.5-flash"
          }),
          new Promise<never>((_, reject) =>
            setTimeout(() => reject(new Error("LLM timeout")), 12000)
          )
        ]);

        console.log(`[ChatService] FAST SEARCH: Returning ${webSources.length} sources in <10s`);

        return {
          content: llmResponse.content,
          role: "assistant",
          webSources: webSources.slice(0, 15)
        };
      } catch (error) {
        console.error("[ChatService] IMMEDIATE SEARCH ERROR:", error);
        // Fall through to normal flow on error
      }
    }

    // PRODUCTION WORKFLOW: Route generation intents (image, slides, docs) through ProductionWorkflowRunner
    // This ensures real artifacts are generated with proper termination guarantees
    // NEW: Allow artifact generation WITH attachments if user explicitly wants OUTPUT artifact
    // (e.g., "genera un documento Word con el resumen de este PDF")
    const hasAttachments = hasRawAttachments || (attachmentContext && attachmentContext.length > 0);
    const intent = classifyIntent(lastUserMessage.content);
    const wantsOutputArtifact = isGenerationIntent(intent);

    // Execute ProductionWorkflowRunner if:
    // 1. No attachments and generation intent detected, OR
    // 2. Has attachments but user explicitly wants to GENERATE an output artifact
    if (!documentMode && !figmaMode && !hasImages && (wantsOutputArtifact || !hasAttachments)) {
      if (wantsOutputArtifact) {
        console.log(`[ChatService] Generation intent detected: ${intent}, routing to ProductionWorkflowRunner${hasAttachments ? ' (with attachment context)' : ''}`);
        try {
          // Include attachment context in the prompt if available
          const enrichedPrompt = hasAttachments && attachmentContext
            ? `${lastUserMessage.content}\n\n[DOCUMENTO DE REFERENCIA]\n${attachmentContext.slice(0, 20000)}`
            : lastUserMessage.content;
          const imageContext = lastImageBase64 ? { image: { lastImageBase64, lastImageId } } : undefined;
          const { run, response } = await productionWorkflowRunner.executeAndWait(enrichedPrompt, imageContext);

          // Build response with artifact information
          let artifactInfo = null;
          if (run.artifacts.length > 0) {
            const artifact = run.artifacts[0];
            // Extract filename from artifact.path for download URL
            const filename = artifact.path ? artifact.path.split('/').pop() : artifact.artifactId;
            artifactInfo = {
              artifactId: artifact.artifactId,
              type: artifact.type,
              mimeType: artifact.mimeType,
              sizeBytes: artifact.sizeBytes,
              downloadUrl: `/api/artifacts/${filename}/download`,
              previewUrl: artifact.previewUrl?.replace('/api/registry/', '/api/') || `/api/artifacts/${filename}/preview`,
              contentUrl: artifact.contentUrl || null,
            };
          }

          return {
            content: response,
            role: "assistant",
            artifact: artifactInfo,
            agentRunId: run.runId,
          };
        } catch (error: any) {
          console.error(`[ChatService] ProductionWorkflowRunner error:`, error);
          return {
            content: `Error al procesar la solicitud: ${error.message || "Error desconocido"}`,
            role: "assistant",
          };
        }
      }
    }

    // PRIMERO: Detectar multi-intent ANTES de routeMessage para evitar que el agent pipeline
    // capture prompts con m√∫ltiples tareas y solo procese la √∫ltima
    if (!documentMode && !figmaMode && !hasImages) {
      try {
        const detection = await multiIntentManager.detectMultiIntent(lastUserMessage.content, {
          messages: messages.map(m => ({ role: m.role, content: m.content })),
          userPreferences: {}
        });

        if (detection.isMultiIntent && detection.confidence >= 0.7) {

          const pipelineResponse = await multiIntentPipeline.execute(
            lastUserMessage.content,
            {
              userId: conversationId,
              conversationId,
              messages: messages.map(m => ({ role: m.role, content: m.content })),
              onProgress: onAgentProgress
            }
          );

          if (pipelineResponse.aggregate.completionStatus === "complete") {
            return {
              content: pipelineResponse.aggregate.summary,
              role: "assistant",
              wasAgentTask: true,
              pipelineSteps: pipelineResponse.plan.length,
              pipelineSuccess: true,
              multiIntentResponse: pipelineResponse
            };
          }

          // Si el pipeline multi-intent falla, continuar con routeMessage normal
        }
      } catch (error) {
        console.error("Multi-intent pipeline error, falling back to routeMessage:", error);
      }
    }

    // SEGUNDO: Si no es multi-intent o fall√≥, usar routeMessage normal
    // BUT: Skip agent mode if we have attachment content - answer directly from document
    if (forceDirectResponse && attachmentContext) {
      console.log("[ChatService] Force direct response mode - skipping agent pipeline for attachment-based query");
      // Fall through to direct LLM response with attachment context
    } else {
      const routeResult = await routeMessage(lastUserMessage.content);

      if (routeResult.decision === "agent" || routeResult.decision === "hybrid") {
        const urls = routeResult.urls || [];

        for (const url of urls) {
          try {
            const sanitizedUrl = sanitizeUrl(url);
            const securityCheck = await checkDomainPolicy(sanitizedUrl);

            if (!securityCheck.allowed) {
              return {
                content: `No puedo acceder a ${url}: ${securityCheck.reason}`,
                role: "assistant"
              };
            }

            const domain = new URL(sanitizedUrl).hostname;
            if (!checkRateLimit(domain, securityCheck.rateLimit)) {
              return {
                content: `L√≠mite de solicitudes alcanzado para ${domain}. Intenta de nuevo en un minuto.`,
                role: "assistant"
              };
            }
          } catch (e) {
            console.error("URL validation error:", e);
          }
        }

        if (!isValidObjective(routeResult.objective || lastUserMessage.content)) {
          return {
            content: "No puedo procesar solicitudes que involucren informaci√≥n sensible o actividades no permitidas.",
            role: "assistant"
          };
        }

        const objective = routeResult.objective || lastUserMessage.content;
        let lastBrowserSessionId: string | null = null;

        // Enforce policy check before running agent pipeline
        const agentPolicyCheck = await enforcePolicyCheck("agent_pipeline", "browser_agent");
        if (!agentPolicyCheck.allowed) {
          return {
            content: `No puedo ejecutar esta tarea: ${agentPolicyCheck.reason}`,
            role: "assistant"
          };
        }

        const pipelineStartTime = Date.now();
        try {
          const pipelineResult = await runPipeline({
            objective,
            conversationId,
            onProgress: (update) => {
              onAgentProgress?.(update);
              if (update.detail?.browserSessionId) {
                lastBrowserSessionId = update.detail.browserSessionId;
              }
            }
          });

          await logToolCall(userId || "anonymous", "agent_pipeline", "browser_agent",
            { objective }, { steps: pipelineResult.steps.length, success: pipelineResult.success },
            pipelineResult.success ? "success" : "error", Date.now() - pipelineStartTime);

          return {
            content: pipelineResult.summary || "Tarea completada.",
            role: "assistant",
            sources: pipelineResult.artifacts
              .filter(a => a.type === "text" && a.name)
              .slice(0, 5)
              .map(a => ({ fileName: a.name!, content: a.content?.slice(0, 200) || "" })),
            webSources: pipelineResult.webSources,
            agentRunId: pipelineResult.runId,
            wasAgentTask: true,
            pipelineSteps: pipelineResult.steps.length,
            pipelineSuccess: pipelineResult.success,
            browserSessionId: lastBrowserSessionId
          };
        } catch (pipelineError) {
          await logToolCall(userId || "anonymous", "agent_pipeline", "browser_agent",
            { objective }, null, "error", Date.now() - pipelineStartTime, String(pipelineError));
          throw pipelineError;
        }
      }
    }
  }

  let contextInfo = "";
  let sources: ChatSource[] = [];
  let webSearchInfo = "";
  let webSources: WebSource[] = [];

  // Define hasAttachments for web search blocking logic
  // Uses raw attachments from request OR presence of extracted content
  const hasAttachments = hasRawAttachments || (attachmentContext && attachmentContext.length > 0);

  // Helper function to extract domain and create favicon URL
  const extractWebSource = (url: string, title: string, snippet?: string, year?: string, imageUrl?: string, siteName?: string, canonicalUrl?: string): WebSource => {
    let domain = "";
    try {
      const urlObj = new URL(url);
      domain = urlObj.hostname.replace(/^www\./, "");
    } catch {
      domain = url.split("/")[2]?.replace(/^www\./, "") || "unknown";
    }
    return {
      url,
      title,
      domain,
      favicon: `https://www.google.com/s2/favicons?domain=${domain}&sz=32`,
      snippet: snippet?.slice(0, 200),
      date: year,
      imageUrl,
      siteName: siteName || domain,
      canonicalUrl: canonicalUrl || url
    };
  };

  // Simple search patterns that should ALWAYS trigger web search regardless of feature flag
  // IMPORTANT: These are BLOCKED when user has attachments - document takes priority
  const SIMPLE_SEARCH_PATTERNS = [
    /dame\s+\d*\s*noticias/i,
    /busca(me)?\s+(noticias|informaci√≥n|info|art√≠culos?)/i,
    /noticias\s+(de|sobre|del)/i,
    /√∫ltimas\s+noticias/i,
    /qu√©\s+(est√°\s+pasando|pasa|hay\s+de\s+nuevo)/i,
    /what('s|\s+is)\s+(happening|new|going\s+on)/i,
    /news\s+(about|from|on)/i,
    /precio\s+(de|del|actual)/i,
    /clima\s+(en|de)/i,
    /weather\s+(in|for)/i,
    /quisiera\s+(que\s+)?(me\s+)?ayud(es|a)\s+a\s+buscar/i,
    /ay√∫dame\s+a\s+buscar/i,
    /buscar\s+\d*\s*art√≠culos?/i,
    /dame\s+\d*\s*art√≠culos?/i,
    /encuentra(me)?\s+\d*\s*(art√≠culos?|informaci√≥n)/i,
    /investiga\s+(sobre|acerca)/i,
    /informaci√≥n\s+(sobre|de|del|acerca)/i,
  ];

  // Patterns that EXPLICITLY request internet search (even with attachments)
  const EXPLICIT_WEB_PATTERNS = [
    /busca\s+(en\s+)?(internet|la\s+web|online)/i,
    /consulta\s+(fuentes?\s+)?(externas?|internet|web)/i,
    /compara\s+(con\s+)?(informaci√≥n\s+)?(p√∫blica|de\s+internet|externa)/i,
    /search\s+(the\s+)?(web|internet|online)/i,
    /look\s+up\s+(on\s+)?(the\s+)?(web|internet)/i,
    /find\s+(on\s+)?(the\s+)?(web|internet)/i,
  ];

  const isSimpleSearchQuery = (text: string) => SIMPLE_SEARCH_PATTERNS.some(p => p.test(text));
  const isExplicitWebRequest = (text: string) => EXPLICIT_WEB_PATTERNS.some(p => p.test(text));

  // CRITICAL: Block web search when attachments are present UNLESS user explicitly requests internet
  const userExplicitlyRequestsWeb = lastUserMessage && isExplicitWebRequest(lastUserMessage.content);
  const forceWebSearch = lastUserMessage && isSimpleSearchQuery(lastUserMessage.content) && !hasAttachments;

  // Observability logging for routing decisions - include intent engine insights
  console.log(`[ChatService:Routing] hasAttachments=${hasAttachments}, forceWebSearch=${forceWebSearch}, userExplicitlyRequestsWeb=${userExplicitlyRequestsWeb}, intent=${intentContext?.primaryIntent || "unknown"}, isMultiIntent=${intentContext?.isMultiIntent || false}`);

  // CRITICAL: Web search is BLOCKED when attachments are present UNLESS user explicitly requests it
  // This prevents the system from ignoring uploaded documents and searching the web instead
  const allowWebSearch = !hasAttachments || userExplicitlyRequestsWeb;

  // Intent-based search optimization: boost web search for research/information-seeking intents
  const intentSuggestsSearch = intentContext?.primaryIntent &&
    ['search', 'research', 'find', 'lookup', 'news', 'information'].some(
      keyword => intentContext.primaryIntent?.toLowerCase().includes(keyword)
    );

  if (hasAttachments && !userExplicitlyRequestsWeb) {
    console.log(`[ChatService:WebSearch] BLOCKED - Document mode active. hasAttachments=${hasAttachments}, userExplicitlyRequestsWeb=${userExplicitlyRequestsWeb}`);
  }

  // Web search: either forced by simple query OR gated by webSearchAuto feature flag
  // GATED: Only allowed when no attachments OR user explicitly requests web
  // Intent-aware: also triggers if intent engine detected a search/research intent
  const shouldSearchWeb = forceWebSearch || featureFlags.webSearchAuto || intentSuggestsSearch;
  if (allowWebSearch && lastUserMessage && needsAcademicSearch(lastUserMessage.content) && shouldSearchWeb) {
    const academicPolicyCheck = await enforcePolicyCheck("academic_search", "google_scholar");
    if (!academicPolicyCheck.allowed) {
      console.log(`[ChatService:WebSearch] Academic search blocked by policy: ${academicPolicyCheck.reason}`);
    } else {
      console.log(`[ChatService:WebSearch] Academic search triggered`);
      const searchStartTime = Date.now();
      try {
        const scholarResults = await searchScholar(lastUserMessage.content, 15);
        await logToolCall(userId || "anonymous", "academic_search", "google_scholar",
          { query: lastUserMessage.content }, { count: scholarResults.length }, "success", Date.now() - searchStartTime);

        if (scholarResults.length > 0) {
          webSearchInfo = "\n\n**Art√≠culos acad√©micos encontrados en Google Scholar:**\n" +
            scholarResults.map((r, i) =>
              `[${i + 1}] Autores: ${r.authors || "No disponible"}\nA√±o: ${r.year || "No disponible"}\nT√≠tulo: ${r.title}\nURL: ${r.url}\nResumen: ${r.snippet}\nCita sugerida: ${r.citation}`
            ).join("\n\n");

          // Capture web sources for citations
          webSources = scholarResults
            .filter(r => r.url)
            .map(r => extractWebSource(r.url, r.title, r.snippet, r.year, r.imageUrl, r.siteName, r.canonicalUrl));
        }
      } catch (error) {
        await logToolCall(userId || "anonymous", "academic_search", "google_scholar",
          { query: lastUserMessage.content }, null, "error", Date.now() - searchStartTime, String(error));
        console.error("Academic search error:", error);
      }
    }
  } else if (allowWebSearch && lastUserMessage && needsWebSearch(lastUserMessage.content) && shouldSearchWeb) {
    const webPolicyCheck = await enforcePolicyCheck("web_search", "duckduckgo");
    if (!webPolicyCheck.allowed) {
      console.log(`[ChatService:WebSearch] Web search blocked by policy: ${webPolicyCheck.reason}`);
    } else {
      console.log(`[ChatService:WebSearch] Web search triggered`);
      const searchStartTime = Date.now();
      try {
        // Request more sources (20) for richer citations
        const searchResults = await searchWeb(lastUserMessage.content, 20);
        await logToolCall(userId || "anonymous", "web_search", "duckduckgo",
          { query: lastUserMessage.content }, { count: searchResults.results.length }, "success", Date.now() - searchStartTime);

        // Include ALL sources found for citations (not just those with extracted content)
        if (searchResults.results.length > 0) {
          webSources = searchResults.results.map(r => extractWebSource(r.url, r.title, r.snippet, undefined, r.imageUrl, r.siteName, r.canonicalUrl));
        }

        if (searchResults.contents.length > 0) {
          webSearchInfo = "\n\n**Informaci√≥n de Internet (actualizada):**\n" +
            searchResults.contents.map((content, i) =>
              `[${i + 1}] ${content.title} (${content.url}):\n${content.content}`
            ).join("\n\n");
        } else if (searchResults.results.length > 0) {
          webSearchInfo = "\n\n**Resultados de b√∫squeda web:**\n" +
            searchResults.results.map((r, i) =>
              `[${i + 1}] ${r.title}: ${r.snippet} (${r.url})`
            ).join("\n");
        }
      } catch (error) {
        await logToolCall(userId || "anonymous", "web_search", "duckduckgo",
          { query: lastUserMessage.content }, null, "error", Date.now() - searchStartTime, String(error));
        console.error("Web search error:", error);
      }
    }
  }

  // RAG/Memory retrieval is gated by memoryEnabled AND explicit user intent
  // Only inject memory context when user explicitly mentions their documents
  const userWantsMemory = lastUserMessage ? detectMemoryIntent(lastUserMessage.content) : false;

  if (useRag && featureFlags.memoryEnabled && lastUserMessage && userWantsMemory) {
    const ragPolicyCheck = await enforcePolicyCheck("memory_retrieval", "rag_search");
    if (!ragPolicyCheck.allowed) {
      console.log(`[ChatService:RAG] Memory retrieval blocked by policy: ${ragPolicyCheck.reason}`);
    } else {
      const ragStartTime = Date.now();
      try {
        const queryEmbedding = await generateEmbedding(lastUserMessage.content);
        const allChunks = await storage.searchSimilarChunks(queryEmbedding, LIMITS.RAG_SIMILAR_CHUNKS, userId);

        // Filter by similarity threshold - only include highly relevant chunks
        const similarChunks = allChunks.filter((chunk: any) => {
          const distance = parseFloat(chunk.distance || "1");
          return distance < LIMITS.RAG_SIMILARITY_THRESHOLD;
        });

        await logToolCall(userId || "anonymous", "memory_retrieval", "rag_search",
          { query: lastUserMessage.content }, { count: similarChunks.length }, "success", Date.now() - ragStartTime);

        if (similarChunks.length > 0) {
          sources = similarChunks.map((chunk: any) => ({
            fileName: chunk.file_name || "Documento",
            content: chunk.content.slice(0, 200) + "..."
          }));

          contextInfo = "\n\nContexto de tus documentos:\n" +
            similarChunks.map((chunk: any, i: number) =>
              `[${i + 1}] ${chunk.file_name || "Documento"}: ${chunk.content}`
            ).join("\n\n");
        }
      } catch (error) {
        await logToolCall(userId || "anonymous", "memory_retrieval", "rag_search",
          { query: lastUserMessage.content }, null, "error", Date.now() - ragStartTime, String(error));
        console.error("RAG search error:", error);
      }
    }
  }

  // Special system prompt for document mode - AI writes clean content only
  const documentModeInstructions = `
REGLAS DE ESCRITURA DE DOCUMENTOS:
1. Escribe SOLO el contenido solicitado, sin explicaciones ni introducciones.
2. NO incluyas frases como "Aqu√≠ est√°...", "A continuaci√≥n...", "Claro, te escribo...", etc.
3. NO hagas preguntas de seguimiento ni pidas confirmaci√≥n.
4. NO incluyas comentarios sobre lo que vas a hacer o has hecho.
5. Escribe el contenido directamente como si estuvieras escribiendo en el documento.
6. Usa formato apropiado: p√°rrafos para Word, datos estructurados para Excel, puntos clave para PPT.
7. Si el usuario pide una lista, escribe solo la lista.
8. Si el usuario pide un p√°rrafo, escribe solo el p√°rrafo.
9. Si el usuario pide editar algo, escribe solo el texto editado/corregido.
10. El contenido se insertar√° directamente en el editor del usuario.

FORMATO DE TEXTO ENRIQUECIDO (se convertir√° a estilos nativos de Office):
- Para texto en **negrita**, usa **doble asterisco**
- Para texto en *cursiva*, usa *asterisco simple*
- Para \`c√≥digo\`, usa \`comillas invertidas\`

F√ìRMULAS MATEM√ÅTICAS - OBLIGATORIO USAR SINTAXIS LaTeX:
- Para f√≥rmulas en l√≠nea: $x^2 + y^2 = z^2$
- Para f√≥rmulas en bloque: $$\\frac{a}{b}$$
- Fracciones: $\\frac{numerador}{denominador}$
- Exponentes: $x^2$, $x^{n+1}$
- Sub√≠ndices: $x_1$, $a_{ij}$
- Ra√≠ces: $\\sqrt{x}$, $\\sqrt[n]{x}$
- Letras griegas: $\\alpha$, $\\beta$, $\\pi$, $\\theta$
- Derivadas: $\\frac{d}{dx}$, $f'(x)$
- Integrales: $\\int_{a}^{b} f(x) dx$
- Sumas: $\\sum_{i=1}^{n} x_i$
- L√≠mites: $\\lim_{x \\to 0}$

IMPORTANTE: SIEMPRE usa $ para envolver f√≥rmulas matem√°ticas:
- CORRECTO: "La funci√≥n $f(x) = x^2$ tiene derivada $f'(x) = 2x$"
- INCORRECTO: "La funci√≥n f(x) = x¬≤" (NO uses caracteres Unicode como ¬≤, ¬≥, ‚Å¥)
- INCORRECTO: "f(x) = 8x‚Å¥ - 6x¬≥" (NO uses super√≠ndices Unicode)
- CORRECTO: "$f(x) = 8x^4 - 6x^3$" (USA LaTeX con $...$)

Escribe contenido limpio y directo.`;

  const excelChartInstructions = `
FORMATO OBLIGATORIO PARA EXCEL:
- SIEMPRE usa formato CSV con valores separados por comas.
- NUNCA uses markdown, asteriscos (**), guiones (-), ni bloques de c√≥digo.
- Cada l√≠nea es una fila de la hoja de c√°lculo.
- Los valores se separan con comas.

COMANDOS DE HOJAS:
- Para crear una NUEVA hoja: [NUEVA_HOJA:Nombre de la Hoja]
- Puedes crear m√∫ltiples hojas en una sola respuesta.

EJEMPLO DE GR√ÅFICOS DE BARRAS con m√∫ltiples hojas:
[NUEVA_HOJA:Ventas 2020-2025]
A√±o,Ventas,Gr√°fico
2020,45000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2021,62000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2022,78000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2023,85000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2024,92000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2025,98000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

[NUEVA_HOJA:Proyecci√≥n 2030-2035]
A√±o,Proyecci√≥n,Gr√°fico
2030,150000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2031,175000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2032,200000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2033,225000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2034,250000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2035,280000,‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

[NUEVA_HOJA:Balance de Ventas]
Concepto,Q1,Q2,Q3,Q4,Total
Ingresos,25000,28000,32000,35000,=B2+C2+D2+E2
Costos,15000,16000,18000,20000,=B3+C3+D3+E3
Utilidad Bruta,=B2-B3,=C2-C3,=D2-D3,=E2-E3,=B4+C4+D4+E4
Gastos Operativos,3000,3500,4000,4500,=B5+C5+D5+E5
Utilidad Neta,=B4-B5,=C4-C5,=D4-D5,=E4-E5,=B6+C6+D6+E6

REGLAS IMPORTANTES:
1. Usa [NUEVA_HOJA:nombre] para crear cada hoja nueva.
2. Despu√©s del comando de hoja, escribe los datos CSV directamente SIN l√≠neas vac√≠as.
3. Para gr√°ficos de barras visuales, usa ‚ñà repetido proporcionalmente.
4. Para f√≥rmulas usa el formato =CELDA+CELDA (ej: =B2+C2 o =SUM(B2:E2)).
5. Las celdas se nombran como en Excel: A1, B2, C3, etc.
6. NO incluyas explicaciones, solo los comandos y datos.
`;

  // Build system prompt - prioritize session contract over legacy config
  const gptSystemPrompt = activeSessionContract
    ? buildSystemPromptWithContext(activeSessionContract)
    : validatedGptConfig?.systemPrompt;

  const documentModePrompt = documentMode ? (
    gptSystemPrompt
      ? `${gptSystemPrompt}

Est√°s ayudando al usuario a crear un documento ${documentMode.type === 'word' ? 'Word' : documentMode.type === 'excel' ? 'Excel' : 'PowerPoint'}.
${documentModeInstructions}${documentMode.type === 'excel' ? excelChartInstructions : ''}${contextInfo}`
      : `Eres un asistente de escritura de documentos. El usuario est√° editando un documento ${documentMode.type === 'word' ? 'Word' : documentMode.type === 'excel' ? 'Excel' : 'PowerPoint'}.
${documentModeInstructions}${documentMode.type === 'excel' ? excelChartInstructions : ''}${contextInfo}`
  ) : null;

  // Check if user explicitly requests document creation
  const lastUserMsgText = messages.filter(m => m.role === "user").pop()?.content?.toLowerCase() || "";
  const wantsDocument = /\b(crea|crear|genera|generar|haz|hacer|escribe|escribir|redacta|redactar|elabora|elaborar)\b.*(documento|word|excel|powerpoint|ppt|archivo|docx|xlsx|pptx)/i.test(lastUserMsgText) ||
    /\b(documento|word|excel|powerpoint|ppt)\b.*(crea|crear|genera|generar|haz|hacer)/i.test(lastUserMsgText);

  // Check if user wants a chart/graph/visualization
  // Code interpreter is gated by the codeInterpreterEnabled feature flag
  const wantsChart = /\b(gr[a√°]fic[oa]|chart|plot|visualiz|histograma|diagrama de barras|pie chart|scatter|l[i√≠]nea|barras)\b/i.test(lastUserMsgText);

  const codeInterpreterPrompt = (wantsChart && featureFlags.codeInterpreterEnabled) ? `
‚ö†Ô∏è OBLIGATORIO - CODE INTERPRETER ACTIVO ‚ö†Ô∏è
El usuario ha solicitado una GR√ÅFICA o VISUALIZACI√ìN. DEBES responder con c√≥digo Python ejecutable.

REGLAS ESTRICTAS:
1. Tu respuesta DEBE contener un bloque \`\`\`python con c√≥digo ejecutable
2. NO describas la gr√°fica con texto - GENERA EL C√ìDIGO
3. NO uses caracteres ASCII (‚ñà, ‚îÄ, etc.) para simular gr√°ficas
4. El c√≥digo se ejecutar√° autom√°ticamente y mostrar√° la gr√°fica real

C√ìDIGO OBLIGATORIO para gr√°fica de barras:
\`\`\`python
import matplotlib.pyplot as plt
import numpy as np

# Datos simulados
years = [2020, 2021, 2022, 2023, 2024, 2025]
values = [450, 520, 610, 580, 720, 850]

plt.figure(figsize=(10, 6))
plt.bar(years, values, color='steelblue', edgecolor='navy')
plt.xlabel('A√±o', fontsize=12)
plt.ylabel('Valor', fontsize=12)
plt.title('Datos Simulados 2020-2025', fontsize=14, fontweight='bold')
plt.grid(axis='y', alpha=0.3, linestyle='--')
plt.tight_layout()
plt.show()
\`\`\`

Para gr√°fica de l√≠neas:
\`\`\`python
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.plot(years, values, marker='o', linewidth=2, markersize=8)
plt.xlabel('A√±o')
plt.ylabel('Valor')
plt.title('Tendencia')
plt.grid(True, alpha=0.3)
plt.show()
\`\`\`

Para gr√°fica circular (pie):
\`\`\`python
import matplotlib.pyplot as plt
labels = ['A', 'B', 'C', 'D']
sizes = [30, 25, 25, 20]
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('Distribuci√≥n')
plt.show()
\`\`\`

RESPONDE AHORA CON UN BLOQUE \`\`\`python QUE CREE LA GR√ÅFICA SOLICITADA.
` : '';

  const documentCapabilitiesPrompt = wantsDocument ? `
CAPACIDADES DE GENERACI√ìN DE DOCUMENTOS:
Puedes crear documentos Word, Excel y PowerPoint. Incluye en tu respuesta un bloque especial con el formato:

\`\`\`document
{
  "type": "word" | "excel" | "ppt",
  "title": "T√≠tulo del documento",
  "content": "Contenido formateado del documento"
}
\`\`\`

Para Word: usa markdown simple (## para t√≠tulos, - para listas).
Para Excel: usa formato de tabla con | columna1 | columna2 | o CSV.
Para PPT: usa ## para t√≠tulos de diapositivas y - para puntos.

El usuario podr√° descargar el documento generado directamente.` : `
IMPORTANTE: Cuando el usuario pida un resumen, an√°lisis o informaci√≥n, responde directamente en texto plano en el chat. 
NO generes documentos Word/Excel/PPT a menos que el usuario lo pida EXPL√çCITAMENTE con frases como "crea un documento", "genera un Word", "haz un PowerPoint", etc.
Si el usuario dice "dame un resumen" o "analiza esto", responde en texto, NO como documento.`;

  // Build user profile context if available
  const userProfileContext = userProfile && (userProfile.nickname || userProfile.occupation || userProfile.bio)
    ? `\n\nInformaci√≥n del usuario:${userProfile.nickname ? `\n- Nombre/Apodo: ${userProfile.nickname}` : ''}${userProfile.occupation ? `\n- Ocupaci√≥n: ${userProfile.occupation}` : ''}${userProfile.bio ? `\n- Bio: ${userProfile.bio}` : ''}`
    : '';

  // Build custom instructions section if present
  const customInstructionsSection = customInstructions
    ? `\n\nInstrucciones personalizadas del usuario:\n${customInstructions}`
    : '';

  // Build response style modifier based on user preference
  const responseStyleModifier = responseStyle !== 'default'
    ? `\n\nEstilo de respuesta preferido: ${responseStyle === 'formal' ? 'formal y profesional' :
      responseStyle === 'casual' ? 'casual y amigable' :
        responseStyle === 'concise' ? 'muy conciso y breve' : ''
    }`
    : '';

  // Build company knowledge context if available
  const companyKnowledgeSection = companyKnowledge && companyKnowledge.length > 0
    ? `\n\n**CONOCIMIENTOS DE LA EMPRESA (usa esta informaci√≥n para responder):**\n${companyKnowledge.map(k => `### ${k.title} [${k.category}]\n${k.content}`).join('\n\n')
    }`
    : '';

  // Current date/time context for real-time awareness
  const now = new Date();
  const currentDateTimeContext = `\n\n**FECHA Y HORA ACTUAL:**
- Fecha: ${now.toLocaleDateString('es-PE', { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric', timeZone: 'America/Lima' })}
- Hora (Per√∫/Lima): ${now.toLocaleTimeString('es-PE', { hour: '2-digit', minute: '2-digit', second: '2-digit', timeZone: 'America/Lima' })}
- Hora UTC: ${now.toISOString()}
Usa esta informaci√≥n para responder preguntas sobre la hora, fecha o d√≠a actual.`;

  const defaultSystemContent = `Eres IliaGPT, un asistente de IA conciso y directo. Responde de forma breve y al punto. Evita introducciones largas y despedidas innecesarias. Ve directo a la respuesta sin rodeos.${currentDateTimeContext}${userProfileContext}${customInstructionsSection}${responseStyleModifier}${companyKnowledgeSection}
${codeInterpreterPrompt}${documentCapabilitiesPrompt}`;

  // Use document mode prompt when in document editing mode
  // Include attachment context for document-based Q&A
  // Combine persistent conversation documents with current attachments
  const fullDocumentContext = persistentDocumentContext + attachmentContext;
  const systemContent = documentModePrompt
    ? documentModePrompt
    : (gptSystemPrompt
      ? `${gptSystemPrompt}\n\n${defaultSystemContent}${webSearchInfo}${contextInfo}${fullDocumentContext}`
      : `${defaultSystemContent}${webSearchInfo}${contextInfo}${fullDocumentContext}`);

  const systemMessage: ChatMessage = {
    role: "system",
    content: systemContent
  };

  // Extract temperature and topP - prioritize contract, fall back to legacy config
  const temperature = activeSessionContract?.temperature ?? validatedGptConfig?.temperature ?? 0.7;
  const topP = activeSessionContract?.topP ?? validatedGptConfig?.topP ?? 1;

  // Handle Figma diagram generation mode
  if (figmaMode && lastUserMessage) {
    const diagramType = detectDiagramType(lastUserMessage.content);

    const flowchartPrompt = `Eres un generador de diagramas de flujo. Analiza la solicitud del usuario y genera un diagrama de flujo estructurado.

DEBES responder √öNICAMENTE con un objeto JSON v√°lido en el siguiente formato:
{
  "title": "T√≠tulo del diagrama",
  "diagramType": "flowchart",
  "nodes": [
    { "id": "node1", "type": "start", "label": "Inicio", "x": 100, "y": 50 },
    { "id": "node2", "type": "process", "label": "Paso 1", "x": 100, "y": 150 },
    { "id": "node3", "type": "decision", "label": "¬øCondici√≥n?", "x": 100, "y": 250 },
    { "id": "node4", "type": "process", "label": "Paso S√≠", "x": 250, "y": 350 },
    { "id": "node5", "type": "process", "label": "Paso No", "x": -50, "y": 350 },
    { "id": "node6", "type": "end", "label": "Fin", "x": 100, "y": 450 }
  ],
  "connections": [
    { "from": "node1", "to": "node2" },
    { "from": "node2", "to": "node3" },
    { "from": "node3", "to": "node4", "label": "S√≠" },
    { "from": "node3", "to": "node5", "label": "No" },
    { "from": "node4", "to": "node6" },
    { "from": "node5", "to": "node6" }
  ]
}

TIPOS DE NODOS:
- "start": Nodo de inicio (√≥valo)
- "end": Nodo de fin (√≥valo)  
- "process": Proceso o acci√≥n (rect√°ngulo)
- "decision": Decisi√≥n/bifurcaci√≥n (rombo)

REGLAS:
1. Cada diagrama DEBE tener exactamente UN nodo "start" y al menos UN nodo "end"
2. Los labels deben ser concisos (m√°ximo 4 palabras)
3. SOLO responde con el JSON, sin explicaciones`;

    const orgchartPrompt = `Eres un generador de organigramas empresariales. Analiza la solicitud del usuario y genera una estructura jer√°rquica.

DEBES responder √öNICAMENTE con un objeto JSON v√°lido en el siguiente formato:
{
  "title": "Organigrama de la Empresa",
  "diagramType": "orgchart",
  "nodes": [
    { "id": "ceo", "type": "role", "label": "Director General", "x": 0, "y": 0 },
    { "id": "cfo", "type": "role", "label": "Director Financiero", "x": 0, "y": 0 },
    { "id": "coo", "type": "role", "label": "Director Operaciones", "x": 0, "y": 0 },
    { "id": "team1", "type": "department", "label": "Equipo Finanzas", "x": 0, "y": 0 },
    { "id": "team2", "type": "department", "label": "Equipo Operaciones", "x": 0, "y": 0 }
  ],
  "connections": [
    { "from": "ceo", "to": "cfo" },
    { "from": "ceo", "to": "coo" },
    { "from": "cfo", "to": "team1" },
    { "from": "coo", "to": "team2" }
  ]
}

TIPOS DE NODOS:
- "role": Cargo o posici√≥n (Director, Gerente, Jefe)
- "department": Departamento o √°rea (Finanzas, Ventas, RRHH)
- "person": Persona espec√≠fica con nombre

REGLAS OBLIGATORIAS:
1. NUNCA uses nodos "start", "end", "Inicio" o "Fin" - esto es un organigrama, NO un diagrama de flujo
2. Debe haber exactamente UN nodo ra√≠z (CEO/Director General) sin padre
3. La estructura debe ser jer√°rquica (√°rbol), sin ciclos
4. Labels deben ser cargos o departamentos reales en espa√±ol
5. Las posiciones x,y ser√°n recalculadas autom√°ticamente, ponlas en 0
6. SOLO responde con el JSON, sin explicaciones
7. NO inventes palabras, usa vocabulario empresarial est√°ndar`;

    const figmaSystemPrompt = diagramType === "orgchart" ? orgchartPrompt : flowchartPrompt;

    try {
      const figmaResponse = await llmGateway.chat(
        [
          { role: "system", content: figmaSystemPrompt },
          { role: "user", content: lastUserMessage.content }
        ],
        {
          model: MODELS.TEXT,
          temperature: 0.2,
          topP: 1,
          userId: conversationId,
          requestId: `figma_${Date.now()}`,
        }
      );

      // Parse the JSON response
      let figmaDiagram: FigmaDiagram | undefined;
      try {
        const jsonMatch = figmaResponse.content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0]);
          figmaDiagram = {
            diagramType: parsed.diagramType || diagramType,
            title: parsed.title || "Diagrama",
            nodes: parsed.nodes || [],
            connections: parsed.connections || []
          };

          // Apply tree layout for org charts
          if (figmaDiagram.diagramType === "orgchart") {
            const validOrgTypes = ["role", "department", "person"];
            const invalidLabels = ["inicio", "fin", "start", "end", "aleta"];

            // Filter out invalid nodes
            const validNodeIds = new Set<string>();
            figmaDiagram.nodes = figmaDiagram.nodes.filter(node => {
              const isValidType = validOrgTypes.includes(node.type);
              const isValidLabel = !invalidLabels.includes(node.label.toLowerCase());
              if (isValidType && isValidLabel) {
                validNodeIds.add(node.id);
                return true;
              }
              console.warn(`Filtering out invalid org chart node: ${node.id} (type: ${node.type}, label: ${node.label})`);
              return false;
            });

            // Filter connections to only reference valid nodes
            figmaDiagram.connections = figmaDiagram.connections.filter(conn =>
              validNodeIds.has(conn.from) && validNodeIds.has(conn.to)
            );

            // Validate the cleaned diagram - reject if still invalid
            const validation = validateOrgChart(figmaDiagram);
            if (!validation.valid) {
              console.warn("Org chart validation errors after filtering:", validation.errors);
              // Reject the diagram entirely if structural issues remain
              figmaDiagram = undefined;
            } else {
              figmaDiagram = applyTreeLayout(figmaDiagram);
            }
          }
        }
      } catch (parseError) {
        console.error("Failed to parse Figma diagram JSON:", parseError);
      }

      if (figmaDiagram && figmaDiagram.nodes.length > 0) {
        const typeLabel = diagramType === "orgchart" ? "organigrama" : "diagrama";
        return {
          content: `Ha creado el ${typeLabel} "${figmaDiagram.title}". Puedes verlo abajo y editarlo en Figma.`,
          role: "assistant",
          figmaDiagram
        };
      } else {
        return {
          content: "No pude generar el diagrama. Por favor, describe la estructura que quieres visualizar con m√°s detalle.",
          role: "assistant"
        };
      }
    } catch (error) {
      console.error("Figma diagram generation error:", error);
      return {
        content: "Hubo un error al generar el diagrama. Por favor, intenta de nuevo.",
        role: "assistant"
      };
    }
  }

  let response;

  if (provider === "gemini") {
    if (hasImages) {
      return {
        content: "Gemini actualmente no soporta an√°lisis de im√°genes en esta versi√≥n. Por favor, selecciona xAI Grok 2 Vision para analizar im√°genes.",
        role: "assistant"
      };
    }


    const geminiMessages: GeminiChatMessage[] = [];

    if (systemMessage.content) {
      geminiMessages.push({
        role: "user",
        parts: [{ text: `[System Instructions]\n${systemMessage.content}\n\n[End System Instructions]` }]
      });
      geminiMessages.push({
        role: "model",
        parts: [{ text: "Entendido. Seguir√© estas instrucciones." }]
      });
    }

    for (const msg of messages) {
      geminiMessages.push({
        role: msg.role === "assistant" ? "model" : "user",
        parts: [{ text: msg.content }]
      });
    }

    const geminiModel = (model as typeof GEMINI_MODELS[keyof typeof GEMINI_MODELS]) || GEMINI_MODELS.FLASH;

    const geminiResponse = await geminiChat(geminiMessages, {
      model: geminiModel,
      temperature,
      topP,
    });

    console.log(`[ChatService] Gemini response: model=${geminiResponse.model}`);

    return {
      content: geminiResponse.content,
      role: "assistant",
      sources,
      webSources: webSources.length > 0 ? webSources : undefined
    };
  } else if (hasImages) {
    const imageContents = images!.map((img: string) => ({
      type: "image_url" as const,
      image_url: { url: img }
    }));

    const lastUserIdx = messages.findLastIndex(m => m.role === "user");
    const messagesWithImages = messages.map((msg, idx) => {
      if (idx === lastUserIdx) {
        return {
          role: msg.role,
          content: [
            ...imageContents,
            { type: "text" as const, text: msg.content || "Analiza esta imagen" }
          ]
        };
      }
      return msg;
    });

    response = await openai.chat.completions.create({
      model: MODELS.VISION,
      messages: [systemMessage, ...messagesWithImages] as OpenAI.Chat.ChatCompletionMessageParam[],
      max_tokens: 4096,
      temperature,
      top_p: topP,
    });

    const content = response.choices[0]?.message?.content || "No response generated";

    return {
      content,
      role: "assistant",
      sources,
      webSources: webSources.length > 0 ? webSources : undefined
    };
  } else {
    const gatewayResponse = await llmGateway.chat(
      [systemMessage, ...messages],
      {
        model: model || MODELS.TEXT,
        temperature,
        topP,
        userId: conversationId,
        requestId: `chat_${Date.now()}`,
      }
    );

    console.log(`[ChatService] LLM Gateway response: ${gatewayResponse.latencyMs}ms, tokens: ${gatewayResponse.usage?.totalTokens || 0}`);

    return {
      content: gatewayResponse.content,
      role: "assistant",
      sources,
      webSources: webSources.length > 0 ? webSources : undefined
    };
  }
}
